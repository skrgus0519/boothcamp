{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6b82288e",
      "metadata": {
        "id": "6b82288e"
      },
      "source": [
        "### RAG 기본 구조 이해하기\n",
        "\n",
        "1. 사전작업(Pre-processing): 데이터 소스를 Vector DB (저장소) 에 문서를 로드-분할-임베딩-저장 \n",
        "\n",
        "- 1단계 문서로드(Document Load): 문서 내용을 불러옴\n",
        "- 2단계 분할(Text Split): 문서를 특정 기준(Chunk) 으로 분할\n",
        "- 3단계 임베딩(Embedding): 분할된(Chunk) 를 임베딩하여 저장\n",
        "- 4단계 벡터DB 저장: 임베딩된 Chunk 를 DB에 저장\n",
        "\n",
        "2. RAG 수행(RunTime) - 5~8 단계\n",
        "\n",
        "- 5단계 검색기(Retriever): 쿼리(Query) 를 바탕으로 DB에서 검색하여 결과를 가져오기 위하여 리트리버를 정의\n",
        "- 6단계 프롬프트: RAG 를 수행하기 위한 프롬프트를 생성. 프롬프트의 context 에는 문서에서 검색된 내용이 입력됨. 프롬프트 엔지니어링을 통하여 답변의 형식을 지정 가능\n",
        "- 7단계 LLM: 모델을 정의 (GPT-3.5, GPT-4, Claude, etc..)\n",
        "- 8단계 Chain: 프롬프트 - LLM - 출력 에 이르는 체인을 생성"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01c423a8",
      "metadata": {
        "id": "01c423a8"
      },
      "source": [
        "## 환경설정\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac5cb321",
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install -U langchain langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Sg4cuF6Ip9Ep",
      "metadata": {
        "id": "Sg4cuF6Ip9Ep"
      },
      "outputs": [],
      "source": [
        "!pip install langsmith python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lOCXQe4xtHPn",
      "metadata": {
        "id": "lOCXQe4xtHPn"
      },
      "outputs": [],
      "source": [
        "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# API 키 정보 로드\n",
        "load_dotenv('./.env')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34687156",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "print(f\"[API KEY]\\n{os.environ['OPENAI_API_KEY']}\")\n",
        "os.environ['LANGCHAIN_PROJECT'] = 'test11'\n",
        "print(f\"[LANGCHAIN_PROJECT]\\n{os.environ['LANGCHAIN_PROJECT']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a224fd32",
      "metadata": {
        "id": "a224fd32"
      },
      "source": [
        "API KEY 를 설정합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zgNuMaDGp_om",
      "metadata": {
        "collapsed": true,
        "id": "zgNuMaDGp_om"
      },
      "outputs": [],
      "source": [
        "pip install langchain-teddynote"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nGKuTxtsqmp9",
      "metadata": {
        "id": "nGKuTxtsqmp9"
      },
      "outputs": [],
      "source": [
        "from langchain_teddynote import logging\n",
        "\n",
        "# 프로젝트 이름을 입력합니다.\n",
        "logging.langsmith(\"test11\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0024d0c5",
      "metadata": {
        "id": "0024d0c5"
      },
      "source": [
        "[LangSmith](https://smith.langchain.com)를 사용하여 체인이나 에이전트 내부에서 정확히 무슨 일이 일어나고 있는지 조사 가능\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2de11a49",
      "metadata": {
        "id": "2de11a49"
      },
      "source": [
        "## 네이버 뉴스 기반 QA(Question-Answering) 챗봇\n",
        "\n",
        "네이버 뉴스기사의 내용에 대해 질문할 수 있는 **뉴스기사 QA 앱** 을 구축할 것입니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "puiooOMMlebQ",
      "metadata": {
        "collapsed": true,
        "id": "puiooOMMlebQ"
      },
      "outputs": [],
      "source": [
        "!pip install langchain-community langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sbOVchN5rNmI",
      "metadata": {
        "collapsed": true,
        "id": "sbOVchN5rNmI"
      },
      "outputs": [],
      "source": [
        "### PDF 기반 QA(Question-Answering) 챗봇으로 변경하는 코드\n",
        "\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "# PDF 파일 로드. 파일의 경로 입력\n",
        "loader = PyPDFLoader(\"data/SPRI_AI_Brief_2023년12월호_F.pdf\")\n",
        "\n",
        "# 페이지 별 문서 로드\n",
        "docs = loader.load()\n",
        "print(f\"문서의 수: {len(docs)}\")\n",
        "\n",
        "# 10번째 페이지의 내용 출력\n",
        "print(f\"\\n[페이지내용]\\n{docs[10].page_content[:500]}\")\n",
        "print(f\"\\n[metadata]\\n{docs[10].metadata}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db57b978",
      "metadata": {},
      "outputs": [],
      "source": [
        "### csv 기반 QA(Question-Answering) 챗봇으로 변경하는 코드\n",
        "\n",
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "\n",
        "# CSV 파일 로드\n",
        "loader = CSVLoader(file_path=\"data/titanic.csv\")\n",
        "docs = loader.load()\n",
        "print(f\"문서의 수: {len(docs)}\")\n",
        "\n",
        "# 10번째 페이지의 내용 출력\n",
        "print(f\"\\n[페이지내용]\\n{docs[10].page_content[:500]}\")\n",
        "print(f\"\\n[metadata]\\n{docs[10].metadata}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06dcdabf",
      "metadata": {},
      "outputs": [],
      "source": [
        "### 폴더 내의 모든 파일 로드하여 QA(Question-Answering) 챗봇으로 변경하는 코드\n",
        "\n",
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "\n",
        "loader = DirectoryLoader(\".\", glob=\"data/*.txt\", show_progress=True)\n",
        "docs = loader.load()\n",
        "\n",
        "print(f\"문서의 수: {len(docs)}\")\n",
        "\n",
        "# 10번째 페이지의 내용 출력\n",
        "print(f\"\\n[페이지내용]\\n{docs[0].page_content[:500]}\")\n",
        "print(f\"\\n[metadata]\\n{docs[0].metadata}\\n\")\n",
        "\n",
        "\n",
        "### 폴더 내의 모든 pdf 로드하여 QA(Question-Answering) 챗봇으로 변경하는 코드\n",
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "\n",
        "loader = DirectoryLoader(\".\", glob=\"data/*.pdf\")\n",
        "docs = loader.load()\n",
        "\n",
        "print(f\"문서의 수: {len(docs)}\\n\")\n",
        "print(\"[메타데이터]\\n\")\n",
        "print(docs[0].metadata)\n",
        "print(\"\\n========= [앞부분] 미리보기 =========\\n\")\n",
        "print(docs[0].page_content[2500:3000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "473655b2",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Python 기반 QA(Question-Answering) 챗봇으로 변경하는 코드\n",
        "\n",
        "from langchain_community.document_loaders import PythonLoader\n",
        "\n",
        "loader = DirectoryLoader(\".\", glob=\"**/*.py\", loader_cls=PythonLoader)\n",
        "docs = loader.load()\n",
        "\n",
        "print(f\"문서의 수: {len(docs)}\\n\")\n",
        "print(\"[메타데이터]\\n\")\n",
        "print(docs[0].metadata)\n",
        "print(\"\\n========= [앞부분] 미리보기 =========\\n\")\n",
        "print(docs[0].page_content[:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8435e8f",
      "metadata": {},
      "outputs": [],
      "source": [
        "### txt 기반 QA(Question-Answering) 챗봇으로 변경하는 코드\n",
        "\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "\n",
        "loader = TextLoader(\"data/appendix-keywords.txt\")\n",
        "docs = loader.load()\n",
        "print(f\"문서의 수: {len(docs)}\")\n",
        "\n",
        "# 10번째 페이지의 내용 출력\n",
        "print(f\"\\n[페이지내용]\\n{docs[0].page_content[:500]}\")\n",
        "print(f\"\\n[metadata]\\n{docs[0].metadata}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3d1b0fc",
      "metadata": {
        "id": "f3d1b0fc"
      },
      "outputs": [],
      "source": [
        "import bs4\n",
        "from langchain import hub\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.vectorstores.faiss import FAISS\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LPaLNIrHsTF5",
      "metadata": {
        "id": "LPaLNIrHsTF5"
      },
      "outputs": [],
      "source": [
        "! pip install pypdf faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f69f249",
      "metadata": {
        "id": "9f69f249"
      },
      "outputs": [],
      "source": [
        "# 뉴스기사 내용을 로드하고, 청크로 나누고, 인덱싱합니다.\n",
        "loader = WebBaseLoader(\n",
        "    web_paths=(\"https://n.news.naver.com/article/296/0000082139\",),\n",
        "    bs_kwargs=dict(\n",
        "        parse_only=bs4.SoupStrainer(\n",
        "            \"div\",\n",
        "            attrs={\"class\": [\"newsct_article _article_body\", \"media_end_head_title\"]},\n",
        "        )\n",
        "    ),\n",
        ")\n",
        "\n",
        "docs = loader.load()\n",
        "print(f\"문서의 수: {len(docs)}\")\n",
        "docs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b4d5bce",
      "metadata": {
        "id": "5b4d5bce"
      },
      "source": [
        "`RecursiveCharacterTextSplitter`는 문서를 지정된 크기의 청크로 나눔\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e9bf670",
      "metadata": {
        "id": "8e9bf670"
      },
      "outputs": [],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "\n",
        "splits = text_splitter.split_documents(docs)\n",
        "len(splits)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49a38783",
      "metadata": {
        "id": "49a38783"
      },
      "source": [
        "`FAISS` 혹은 `Chroma`와 같은 vectorstore는 이러한 청크를 바탕으로 문서의 벡터 표현을 생성\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "62a8ca04",
      "metadata": {
        "id": "62a8ca04"
      },
      "outputs": [],
      "source": [
        "# 벡터스토어를 생성합니다.\n",
        "vectorstore = FAISS.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
        "\n",
        "# 뉴스에 포함되어 있는 정보를 검색하고 생성합니다.\n",
        "retriever = vectorstore.as_retriever()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00a89f55",
      "metadata": {
        "id": "00a89f55"
      },
      "source": [
        "`vectorstore.as_retriever()`를 통해 생성된 검색기는 프롬프트와 `ChatOpenAI` 모델을 사용하여 새로운 내용을 생성\n",
        "\n",
        "`StrOutputParser`는 생성된 결과를 문자열로 파싱\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "a59f677c",
      "metadata": {
        "id": "a59f677c"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "prompt = PromptTemplate.from_template(\n",
        "    \"\"\"당신은 질문-답변(Question-Answering)을 수행하는 친절한 AI 어시스턴트입니다. 당신의 임무는 주어진 문맥(context) 에서 주어진 질문(question) 에 답하는 것입니다.\n",
        "검색된 다음 문맥(context) 을 사용하여 질문(question) 에 답하세요. 만약, 주어진 문맥(context) 에서 답을 찾을 수 없다면, 답을 모른다면 `주어진 정보에서 질문에 대한 정보를 찾을 수 없습니다` 라고 답하세요.\n",
        "한글로 답변해 주세요. 단, 기술적인 용어나 이름은 번역하지 않고 그대로 사용해 주세요.\n",
        "\n",
        "#Question:\n",
        "{question}\n",
        "\n",
        "#Context:\n",
        "{context}\n",
        "\n",
        "#Answer:\"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "6d16128d",
      "metadata": {
        "id": "6d16128d"
      },
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "\n",
        "# 체인을 생성합니다.\n",
        "rag_chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be9370eb",
      "metadata": {
        "id": "be9370eb"
      },
      "source": [
        "스트리밍 출력을 위하여 `stream_response` 를 사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "78fed977",
      "metadata": {
        "id": "78fed977"
      },
      "outputs": [],
      "source": [
        "from langchain_teddynote.messages import stream_response"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4948a029",
      "metadata": {
        "id": "4948a029"
      },
      "source": [
        "\n",
        "\n",
        "> [LangSmith Trace](https://smith.langchain.com/o/e738ca73-da9f-5fcd-86bb-d729db658172)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78275b37",
      "metadata": {
        "id": "78275b37"
      },
      "outputs": [],
      "source": [
        "answer = rag_chain.stream(\"새로운 수면법을 알려줘..\")\n",
        "# # 제너레이터에서 데이터를 하나씩 모아서 문자열로 합치기\n",
        "# answer_content = ''.join([chunk for chunk in answer])\n",
        "\n",
        "# # 결과 출력\n",
        "# print(answer_content)\n",
        "stream_response(answer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93c96f34",
      "metadata": {
        "id": "93c96f34"
      },
      "outputs": [],
      "source": [
        "answer = rag_chain.stream(\"뉴스기사의 새로운 수면법을 찾아서 이를 영어로 번역해줘.\")\n",
        "stream_response(answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fd1f686",
      "metadata": {
        "id": "6fd1f686"
      },
      "outputs": [],
      "source": [
        "answer = rag_chain.stream(\"새로운 수면 법을 bullet points 형식으로 작성해 주세요.\")\n",
        "stream_response(answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f507cd6b",
      "metadata": {
        "id": "f507cd6b"
      },
      "outputs": [],
      "source": [
        "answer = rag_chain.stream(\"삼성전자 임직원 숫자는 몇명인가요?\")\n",
        "stream_response(answer)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
