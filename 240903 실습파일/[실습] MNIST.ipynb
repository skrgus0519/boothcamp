{"cells":[{"cell_type":"markdown","metadata":{"id":"9PKMyuI5n7Af"},"source":["# MNIST 데이터셋\n","\n","## 개요\n","MNIST 데이터셋은 손으로 쓴 숫자들의 대규모 데이터베이스로, 기계 학습 분야에서 이미지 인식 알고리즘을 학습시키고 테스트하는 데 가장 대표적으로 사용됩니다. 이 데이터셋은 간단한 이미지 처리 시스템의 성능을 벤치마킹하고 다양한 패턴 인식 방법을 비교하는 기준으로 사용됩니다.\n","\n","(링크: https://www.kaggle.com/c/mnist-en/overview)\n","\n","## 구성\n","- **훈련 데이터**: 60,000개의 예제\n","- **테스트 데이터**: 10,000개의 예제\n","- **이미지 크기**: 28x28 픽셀\n","- **채널**: 흑백 (1채널)\n","- **라벨**: 0부터 9까지의 숫자\n","\n"]},{"cell_type":"markdown","metadata":{"id":"v9WPUE98oty1"},"source":["### 1. MNIST 데이터 불러오기 (전처리 포함)\n","\n","코드 설명:\n","\n","- 라이브러리 및 데이터셋 임포트: TensorFlow 및 Keras 라이브러리에서 필요한 모듈을 임포트합니다. MNIST 데이터셋은 손으로 쓴 숫자 이미지를 포함하고 있습니다.\n","\n","- 데이터 로딩: mnist.load_data() 함수를 사용해 MNIST 데이터셋을 로드합니다. 이 함수는 훈련 세트(X_train, y_train)와 테스트 세트(X_test, y_test)를 반환합니다.\n","\n","- 데이터 전처리: 이미지 데이터(X_train, X_test)는 28x28 픽셀 크기로, 이를 784개의 피처로 일렬로 변환하고 255로 나누어 정규화합니다.\n","\n","- 레이블 원-핫 인코딩: to_categorical 함수를 사용해 레이블을 원-핫 인코딩 형식으로 변환합니다. 이는 분류 문제에서 클래스 레이블을 효과적으로 처리하기 위함입니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nR9rTilGBHHP"},"outputs":[],"source":["# 필요 라이브러리 import\n","import tensorflow as tf\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.utils import to_categorical\n","\n","# 전체 데이터 불러오기\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","# (훈련용_data , 테스트용_data) , (훈련용_target , 테스트용_target) = mnist.load_data()\n","\n","# 데이터 전처리\n","X_train = X_train.reshape(-1, 28*28).astype('float32') / 255\n","X_test = X_test.reshape(-1, 28*28).astype('float32') / 255\n","\n","# 레이블 원-핫 인코딩\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)"]},{"cell_type":"markdown","metadata":{"id":"Jm4qfKm9nv4I"},"source":["### 2. 모델 생성하기\n","\n","코드 설명:\n","\n","- 모델 정의: Sequential 모델을 사용하여 레이어를 순차적으로 쌓습니다.\n","\n","- 레이어 추가:\n","  \n","  - Dense(512, activation='relu', input_shape=(784,)): 첫 번째 숨겨진 레이어는 784개의 입력 특성을 받아 512개의 노드를 가지며, 활성화 함수로 'relu'를 사용합니다.\n","  \n","  - 그 후에 더 작은 노드를 가진 여러 Dense 레이어가 연속적으로 추가되며, 마지막 레이어는 10개의 출력 노드(클래스 수)와 'softmax' 활성화 함수를 사용합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EYDkQ6FoB3lV"},"outputs":[],"source":["# Sequential, Dense 레이어 import\n","\n","# 모델 생성\n","model = "]},{"cell_type":"markdown","metadata":{"id":"l0lJvCElqGDS"},"source":["### 3. 모델 컴파일하기\n","\n","코드 설명:\n","\n","- 컴파일: 모델을 컴파일하는 단계에서는, 손실 함수로 'categorical_crossentropy'를 사용하고, 최적화 알고리즘으로 'adam'을 지정합니다.\n","  - 또한 평가 지표로 'accuracy'를 추가합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-F90GP6rB4_k"},"outputs":[],"source":["# 모델 컴파일\n"]},{"cell_type":"markdown","metadata":{"id":"IC4wAPmmqWF3"},"source":["### 4. 모델 학습하기"]},{"cell_type":"markdown","metadata":{"id":"duTyA8IXqZuV"},"source":["코드 설명:\n","\n","- 훈련: model.fit 메소드를 사용하여 모델을 훈련시킵니다. 여기서는 20번의 에폭 동안, 배치 크기를 128로 설정하고, 훈련 데이터의 20%를 검증 데이터로 사용합니다.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c6MRd-PaCw-o"},"outputs":[],"source":["# 모델 학습\n"]},{"cell_type":"markdown","metadata":{"id":"0yre74qDqgWl"},"source":["### 5. 모델 평가하기\n","\n","코드 설명:\n","\n","- 평가: model.evaluate 메소드를 사용하여 테스트 데이터셋을 기반으로 모델을 평가합니다.\n","  - 반환된 손실(loss)과 정확도(accuracy)를 출력하여 모델의 성능을 확인합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PQ9tdCqyCyTo"},"outputs":[],"source":["# 모델 평가\n","loss, accuracy = \n","print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")"]},{"cell_type":"markdown","metadata":{"id":"UA_5ByoLqyaM"},"source":["### 6. 추론 결과 시각화\n","\n","코드 설명:\n","\n","- 테스트 데이터 샘플 추출: np.random.choice를 사용하여 무작위로 3개의 테스트 샘플을 선택합니다.\n","\n","- 모델 예측 및 시각화:\n","  - 각 샘플에 대해 예측을 수행하고, 해당 샘플의 이미지와 예측된 숫자, 실제 레이블을 matplotlib를 사용하여 시각화합니다.\n","  - 각 클래스에 대한 예측 확률을 바 그래프로 표시하여 모델이 어떤 클래스에 대해 높은 확신을 가지고 예측하는지 확인합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zs_4LRWnElt2"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# 테스트 데이터에서 3개 샘플 추출\n","indices = np.random.choice(range(len(X_test)), 3)\n","samples = X_test[indices]\n","predictions = model.predict(samples)\n","\n","# 예측 결과 및 확률 시각화\n","fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(12, 8))\n","for i, (sample, prediction) in enumerate(zip(samples, predictions)):\n","    # 이미지 출력\n","    ax = axes[0, i]\n","    ax.imshow(sample.reshape(28, 28), cmap='gray')\n","    ax.set_title(f\"Predicted: {np.argmax(prediction)}, Actual: {np.argmax(y_test[indices[i]])}\")\n","    ax.axis('off')\n","\n","    # 확률 바 그래프 출력\n","    ax = axes[1, i]\n","    bar_list = ax.bar(range(10), prediction, color='gray')\n","    bar_list[np.argmax(prediction)].set_color('blue')\n","    bar_list[np.argmax(y_test[indices[i]])].set_color('red')\n","    ax.set_ylim([0, 1])\n","    ax.set_xticks(range(10))\n","    ax.set_title(\"Prediction Probabilities\")\n","\n","plt.tight_layout()\n","plt.show()"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOww7Z5nJwo2XN+MQYUnz+c","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
