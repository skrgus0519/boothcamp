{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [LangGraph를 활용한 데이터 분석] \n",
    "\n",
    "vs community 2022 버전 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| STEP                  | Action                                                       | Next Step                                                                 |\n",
    "|-----------------------|--------------------------------------------------------------|---------------------------------------------------------------------------|\n",
    "| Start                 | Initialize the workflow                                      | retrieve_data                                                             |\n",
    "| retrieve_data         | 데이터를 불러오고 전처리                                        | train_model                                                               |\n",
    "| train_model           | Train the Decision Tree model 파라미터 변경된 걸로 재학습시키기    | evaluate_model                                                            |\n",
    "| evaluate_model        | Evaluate the model's F1 score (평가 score에 따라서 분기가 3개로 나감) | visualize_performance (if F1 score > goal_threshold)                      |\n",
    "|                       |                                                              | adjust_parameters (if F1 score ≤ goal_threshold and iterations < 20)      |\n",
    "|                       |                                                              | handle_stop_condition (if iterations ≥ 20)                                |\n",
    "| adjust_parameters     | max_depth를 하나씩 증가시키기                                   | train_model                                                               |\n",
    "| handle_stop_condition | Stop the workflow due to reaching the maximum iterations 정해놓은 run 내에서 결과를 찾지 못하면 종료 | END                                                                       |\n",
    "| visualize_performance | 모델 결과가 나오면 시각화 및 저장                                   | END                                                                       |\n",
    "| END                   | End of the workflow                                          | -                                                                         |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# api key\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langgraph-checkpoint-sqlite langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from typing import TypedDict, Optional\n",
    "import matplotlib.pyplot as plt\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "# Define the GraphState class\n",
    "class GraphState(TypedDict):\n",
    "    data: Optional[pd.DataFrame] = None # 훈련 및 테스트 모델에 사용될 데이터셋을 저장 전처리된 특성 열을 포함한 pandas DataFrame\n",
    "    target: Optional[pd.Series] = None # 데이터셋의 타겟(레이블)을 저장 pandas Series 형태\n",
    "    params: Optional[dict] = None #\t모델 훈련에 사용될 하이퍼파라미터를 저장 딕셔너리 형태로 키와 값으로 구성\n",
    "    model: Optional[DecisionTreeClassifier] = None # 훈련된 결정 트리 모델을 저장 DecisionTreeClassifier 객체\n",
    "    f1_score: Optional[float] = None # 모델의 평가 지표인 F1 점수를 저장\n",
    "    response: Optional[str] = None # 현재 상태에 대한 응답 메시지를 저장 주로 디버깅이나 로깅 목적으로 사용\n",
    "    goal_threshold: Optional[float] = None # 모델이 도달해야 하는 목표 F1 점수를 저장\n",
    "    X_test: Optional[pd.DataFrame] = None # 테스트 데이터셋의 특성 데이터를 저장 pandas DataFrame 형태\n",
    "    y_test: Optional[pd.Series] = None # 테스트 데이터셋의 타겟(레이블) 데이터를 저장 pandas Series 형태\n",
    "    history: Optional[list] = None # 각 반복마다 모델의 파라미터와 F1 점수를 저장한 이력 리스트\n",
    "    iterations: Optional[int] = None # \t모델 훈련 반복 횟수를 저장\n",
    "\n",
    "# Load and preprocess the data\n",
    "def retrieve_data(state: GraphState) -> GraphState:\n",
    "    url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
    "    df = pd.read_csv(url)\n",
    "    \n",
    "    # Preprocessing steps\n",
    "    df.drop(columns=['Name', 'Ticket', 'Cabin'], inplace=True)\n",
    "    # Replacing inplace=True with direct assignment\n",
    "    df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "    df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    le = LabelEncoder()\n",
    "    df['Sex'] = le.fit_transform(df['Sex'])\n",
    "    df['Embarked'] = le.fit_transform(df['Embarked'])\n",
    "    \n",
    "    target = df['Survived']\n",
    "    df.drop(columns=['Survived'], inplace=True)\n",
    "    \n",
    "    return {**state, \"data\": df, \"target\": target, \"params\": {\"max_depth\": 2}, \"history\": [], \"iterations\": 0}\n",
    "\n",
    "# Train the model\n",
    "def train_model(state: GraphState) -> GraphState:\n",
    "    data = state[\"data\"]\n",
    "    target = state[\"target\"]\n",
    "    params = state[\"params\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.3, random_state=42)\n",
    "    model = DecisionTreeClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    return {**state, \"model\": model, \"X_test\": X_test, \"y_test\": y_test}\n",
    "\n",
    "# # Evaluate the model\n",
    "# def evaluate_model(state: GraphState) -> GraphState:\n",
    "#     model = state[\"model\"]\n",
    "#     X_test = state[\"X_test\"]\n",
    "#     y_test = state[\"y_test\"]\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     f1_score_value = f1_score(y_test, y_pred, average='weighted')\n",
    "#     history = state[\"history\"]\n",
    "#     history.append({\"params\": state[\"params\"].copy(), \"f1_score\": f1_score_value})\n",
    "#     return {**state, \"f1_score\": f1_score_value, \"response\": f\"Model F1 score: {f1_score_value:.2f}\", \"history\": history}\n",
    "\n",
    "# Evaluate the model\n",
    "def evaluate_model(state: GraphState) -> GraphState:\n",
    "    model = state[\"model\"]\n",
    "    X_test = state[\"X_test\"]\n",
    "    y_test = state[\"y_test\"]\n",
    "    y_pred = model.predict(X_test)\n",
    "    f1_score_value = f1_score(y_test, y_pred, average='weighted')\n",
    "    history = state[\"history\"]\n",
    "    \n",
    "    # Append current results to history\n",
    "    history.append({\"params\": state[\"params\"].copy(), \"f1_score\": f1_score_value})\n",
    "    \n",
    "    # Print each entry in the history one by one\n",
    "    for entry in history:\n",
    "        print(f\"Max Depth: {entry['params']['max_depth']}, F1 Score: {entry['f1_score']}\")\n",
    "    \n",
    "    return {**state, \"f1_score\": f1_score_value, \"response\": f\"Model F1 score: {f1_score_value:.2f}\", \"history\": history}\n",
    "\n",
    "\n",
    "# Adjust parameters\n",
    "def adjust_parameters(state: GraphState) -> GraphState:\n",
    "    params = state[\"params\"]\n",
    "    params[\"max_depth\"] += 1\n",
    "    iterations = state[\"iterations\"] + 1\n",
    "    print(f\"Adjusting parameters: Iteration {iterations}, Max Depth {params['max_depth']}\")\n",
    "    return {**state, \"params\": params, \"iterations\": iterations}\n",
    "\n",
    "# Check if the accuracy is sufficient\n",
    "def is_sufficient_accuracy(state: GraphState) -> str:\n",
    "    goal_threshold = state[\"goal_threshold\"]\n",
    "    if state[\"f1_score\"] and state[\"f1_score\"] > goal_threshold:\n",
    "        return \"sufficient\"\n",
    "    if state[\"iterations\"] and state[\"iterations\"] >= 20:\n",
    "        return \"stop\"\n",
    "    return \"insufficient\"\n",
    "\n",
    "\n",
    "# Handle stop condition\n",
    "def handle_stop_condition(state: GraphState) -> GraphState:\n",
    "    final_f1_score = state[\"f1_score\"]  # 최종 F1 Score\n",
    "    print(f\"최종 Final F1 Score: {final_f1_score:.4f}\")  # 최종 F1 Score 출력\n",
    "    return {**state, \"response\": \"Stopping the workflow due to reaching the maximum iterations.\"}\n",
    "\n",
    "# Visualize the performance\n",
    "def visualize_performance(state: GraphState) -> GraphState:\n",
    "    history = state[\"history\"]\n",
    "    depths = [entry[\"params\"][\"max_depth\"] for entry in history]\n",
    "    f1_scores = [entry[\"f1_score\"] for entry in history]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(depths, f1_scores, marker='o', linestyle='-', color='b')\n",
    "    plt.title('Model Performance vs. Max Depth')\n",
    "    plt.xlabel('Max Depth')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.grid(True)\n",
    "    plot_filename = 'model_performance.png'\n",
    "    plt.savefig(plot_filename)\n",
    "    plt.close()\n",
    "    return {**state, \"response\": f\"Model training complete. Performance plot saved as '{plot_filename}'\", \"plot_filename\": plot_filename}\n",
    "\n",
    "# Initialize the state graph\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Add nodes to the workflow\n",
    "workflow.add_node(\"retrieve_data\", retrieve_data)\n",
    "workflow.add_node(\"train_model\", train_model)\n",
    "workflow.add_node(\"evaluate_model\", evaluate_model)\n",
    "workflow.add_node(\"adjust_parameters\", adjust_parameters)\n",
    "workflow.add_node(\"handle_stop_condition\", handle_stop_condition)\n",
    "workflow.add_node(\"visualize_performance\", visualize_performance)\n",
    "\n",
    "# Add edges to the workflow\n",
    "workflow.add_edge(\"retrieve_data\", \"train_model\")\n",
    "workflow.add_edge(\"train_model\", \"evaluate_model\")\n",
    "\n",
    "# Add conditional edges for retraining if accuracy is insufficient\n",
    "workflow.add_conditional_edges(\n",
    "    \"evaluate_model\",\n",
    "    is_sufficient_accuracy,\n",
    "    {\n",
    "        \"sufficient\": \"visualize_performance\",\n",
    "        \"insufficient\": \"adjust_parameters\",\n",
    "        \"stop\": \"handle_stop_condition\"\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"adjust_parameters\", \"train_model\")\n",
    "workflow.add_edge(\"handle_stop_condition\", END)\n",
    "workflow.add_edge(\"visualize_performance\", END)\n",
    "# Set entry point\n",
    "workflow.set_entry_point(\"retrieve_data\")\n",
    "\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "# Increase the recursion limit\n",
    "config = RunnableConfig(recursion_limit=2 + 3 * 20 + 3, configurable={\"thread_id\": \"THREAD_ID\"})\n",
    "\n",
    "# Initialize SqliteSaver (사용 못함)\n",
    "# memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "\n",
    "# Compile the workflow with checkpointing\n",
    "app = workflow.compile()\n",
    "\n",
    "# Example input with goal_threshold\n",
    "inputs = {\n",
    "    \"goal_threshold\": 0.81 #80\n",
    "}\n",
    "result = app.invoke(inputs, config=config)\n",
    "\n",
    "# Print the final result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the 'history' part from the result\n",
    "history = result.get('history', [])\n",
    "# Print the extracted history\n",
    "print(\"Extracted History:\")\n",
    "for entry in history:\n",
    "    print(f\"Max Depth: {entry['params']['max_depth']}, F1 Score: {entry['f1_score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from IPython.display import Image, display\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
