{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Colab 데이터 로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgZG8gewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwoKICAgICAgbGV0IHBlcmNlbnREb25lID0gZmlsZURhdGEuYnl0ZUxlbmd0aCA9PT0gMCA/CiAgICAgICAgICAxMDAgOgogICAgICAgICAgTWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCk7CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPSBgJHtwZXJjZW50RG9uZX0lIGRvbmVgOwoKICAgIH0gd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCk7CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          }
        },
        "id": "szZksOaYJGw6",
        "outputId": "adaf675c-8d64-443d-c313-ffe17188b8e9"
      },
      "outputs": [],
      "source": [
        "#Step 1.분석할 데이터가 저장된 파일을 불러와서 변수에 할당합니다.\n",
        "from google.colab import files\n",
        "myfile = files.upload()\n",
        "import io\n",
        "import pandas as pd\n",
        "#pd.read_csv로 csv파일 불러오기\n",
        "src_data = pd.read_csv(io.BytesIO(myfile['와인.csv']),\n",
        "                       encoding='cp949')\n",
        "src_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 로컬 데이터 로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>알콜도수</th>\n",
              "      <th>당도</th>\n",
              "      <th>산도_ph</th>\n",
              "      <th>종류</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9.4</td>\n",
              "      <td>1.9</td>\n",
              "      <td>3.51</td>\n",
              "      <td>레드와인</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9.8</td>\n",
              "      <td>2.6</td>\n",
              "      <td>3.20</td>\n",
              "      <td>레드와인</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9.8</td>\n",
              "      <td>2.3</td>\n",
              "      <td>3.26</td>\n",
              "      <td>레드와인</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9.8</td>\n",
              "      <td>1.9</td>\n",
              "      <td>3.16</td>\n",
              "      <td>레드와인</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9.4</td>\n",
              "      <td>1.9</td>\n",
              "      <td>3.51</td>\n",
              "      <td>레드와인</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6492</th>\n",
              "      <td>11.2</td>\n",
              "      <td>1.6</td>\n",
              "      <td>3.27</td>\n",
              "      <td>화이트와인</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6493</th>\n",
              "      <td>9.6</td>\n",
              "      <td>8.0</td>\n",
              "      <td>3.15</td>\n",
              "      <td>화이트와인</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6494</th>\n",
              "      <td>9.4</td>\n",
              "      <td>1.2</td>\n",
              "      <td>2.99</td>\n",
              "      <td>화이트와인</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6495</th>\n",
              "      <td>12.8</td>\n",
              "      <td>1.1</td>\n",
              "      <td>3.34</td>\n",
              "      <td>화이트와인</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6496</th>\n",
              "      <td>11.8</td>\n",
              "      <td>0.8</td>\n",
              "      <td>3.26</td>\n",
              "      <td>화이트와인</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6497 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      알콜도수   당도  산도_ph     종류\n",
              "0      9.4  1.9   3.51   레드와인\n",
              "1      9.8  2.6   3.20   레드와인\n",
              "2      9.8  2.3   3.26   레드와인\n",
              "3      9.8  1.9   3.16   레드와인\n",
              "4      9.4  1.9   3.51   레드와인\n",
              "...    ...  ...    ...    ...\n",
              "6492  11.2  1.6   3.27  화이트와인\n",
              "6493   9.6  8.0   3.15  화이트와인\n",
              "6494   9.4  1.2   2.99  화이트와인\n",
              "6495  12.8  1.1   3.34  화이트와인\n",
              "6496  11.8  0.8   3.26  화이트와인\n",
              "\n",
              "[6497 rows x 4 columns]"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "src_data = pd.read_csv('와인.csv', encoding='cp949')\n",
        "src_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 공통 실습 코드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMeKY5D9JOd2",
        "outputId": "75c94217-0bb6-4c0b-fa02-8507cb3e8cee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "종류\n",
            "1    4898\n",
            "0    1599\n",
            "Name: count, dtype: int64\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "#Step 2.주어진 데이터를 훈련용 데이터와 검증용 데이터로 나눕니다\n",
        "import numpy as np\n",
        "data = src_data[['알콜도수','당도','산도_ph']].to_numpy()\n",
        "\n",
        "# '레드와인':0, '화이트와인':1 mapping\n",
        "target = src_data['종류'].map({'레드와인':0, '화이트와인':1})\n",
        "print(target.value_counts())\n",
        "print(sum(target.isna()))\n",
        "\n",
        "# train, test 분리\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_data, test_data, train_target, test_target = train_test_split(\n",
        "    data, target, test_size=0.2, random_state=40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdsI-Im6JuTk",
        "outputId": "74f6723e-155c-4ab8-b228-6298efd12bb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\qq\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7641 - loss: 0.1525 - precision_1: 0.7648 - recall_1: 0.9946 - val_accuracy: 0.8567 - val_loss: 0.1104 - val_precision_1: 0.9070 - val_recall_1: 0.9012\n",
            "Epoch 2/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.1147 - precision_1: 0.8736 - recall_1: 0.9249 - val_accuracy: 0.8413 - val_loss: 0.1056 - val_precision_1: 0.9205 - val_recall_1: 0.8626\n",
            "Epoch 3/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8445 - loss: 0.1120 - precision_1: 0.8880 - recall_1: 0.9080 - val_accuracy: 0.8625 - val_loss: 0.0953 - val_precision_1: 0.9141 - val_recall_1: 0.9012\n",
            "Epoch 4/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8618 - loss: 0.1027 - precision_1: 0.9053 - recall_1: 0.9134 - val_accuracy: 0.8615 - val_loss: 0.0965 - val_precision_1: 0.9183 - val_recall_1: 0.8947\n",
            "Epoch 5/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8534 - loss: 0.0992 - precision_1: 0.9005 - recall_1: 0.9087 - val_accuracy: 0.8654 - val_loss: 0.0955 - val_precision_1: 0.9176 - val_recall_1: 0.9012\n",
            "Epoch 6/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8547 - loss: 0.1047 - precision_1: 0.8999 - recall_1: 0.9070 - val_accuracy: 0.8596 - val_loss: 0.0951 - val_precision_1: 0.9094 - val_recall_1: 0.9024\n",
            "Epoch 7/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8559 - loss: 0.1053 - precision_1: 0.8983 - recall_1: 0.9117 - val_accuracy: 0.8625 - val_loss: 0.1026 - val_precision_1: 0.9119 - val_recall_1: 0.9037\n",
            "Epoch 8/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8679 - loss: 0.1005 - precision_1: 0.9072 - recall_1: 0.9190 - val_accuracy: 0.8644 - val_loss: 0.0985 - val_precision_1: 0.8816 - val_recall_1: 0.9461\n",
            "Epoch 9/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8707 - loss: 0.0944 - precision_1: 0.9017 - recall_1: 0.9316 - val_accuracy: 0.8625 - val_loss: 0.0946 - val_precision_1: 0.8995 - val_recall_1: 0.9191\n",
            "Epoch 10/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8619 - loss: 0.1068 - precision_1: 0.9008 - recall_1: 0.9163 - val_accuracy: 0.8462 - val_loss: 0.1002 - val_precision_1: 0.8742 - val_recall_1: 0.9281\n",
            "Epoch 11/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8542 - loss: 0.1055 - precision_1: 0.8939 - recall_1: 0.9151 - val_accuracy: 0.8615 - val_loss: 0.0983 - val_precision_1: 0.8994 - val_recall_1: 0.9178\n",
            "Epoch 12/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8464 - loss: 0.1061 - precision_1: 0.8862 - recall_1: 0.9106 - val_accuracy: 0.8615 - val_loss: 0.0987 - val_precision_1: 0.9045 - val_recall_1: 0.9114\n",
            "Epoch 13/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8507 - loss: 0.1083 - precision_1: 0.8830 - recall_1: 0.9187 - val_accuracy: 0.8673 - val_loss: 0.0948 - val_precision_1: 0.8991 - val_recall_1: 0.9268\n",
            "Epoch 14/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8613 - loss: 0.1013 - precision_1: 0.8931 - recall_1: 0.9255 - val_accuracy: 0.8615 - val_loss: 0.0946 - val_precision_1: 0.8994 - val_recall_1: 0.9178\n",
            "Epoch 15/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8642 - loss: 0.0983 - precision_1: 0.8990 - recall_1: 0.9260 - val_accuracy: 0.8615 - val_loss: 0.0983 - val_precision_1: 0.8877 - val_recall_1: 0.9332\n",
            "Epoch 16/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8647 - loss: 0.0980 - precision_1: 0.8951 - recall_1: 0.9273 - val_accuracy: 0.8615 - val_loss: 0.0948 - val_precision_1: 0.9065 - val_recall_1: 0.9089\n",
            "Epoch 17/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8708 - loss: 0.0973 - precision_1: 0.9084 - recall_1: 0.9231 - val_accuracy: 0.8625 - val_loss: 0.0945 - val_precision_1: 0.9077 - val_recall_1: 0.9089\n",
            "Epoch 18/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8671 - loss: 0.1009 - precision_1: 0.8960 - recall_1: 0.9303 - val_accuracy: 0.8606 - val_loss: 0.0967 - val_precision_1: 0.8819 - val_recall_1: 0.9397\n",
            "Epoch 19/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8655 - loss: 0.0952 - precision_1: 0.8956 - recall_1: 0.9307 - val_accuracy: 0.8587 - val_loss: 0.0951 - val_precision_1: 0.8911 - val_recall_1: 0.9243\n",
            "Epoch 20/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8669 - loss: 0.0996 - precision_1: 0.8989 - recall_1: 0.9276 - val_accuracy: 0.8615 - val_loss: 0.1019 - val_precision_1: 0.9428 - val_recall_1: 0.8678\n",
            "Epoch 21/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8619 - loss: 0.0973 - precision_1: 0.9038 - recall_1: 0.9157 - val_accuracy: 0.8558 - val_loss: 0.0985 - val_precision_1: 0.8821 - val_recall_1: 0.9320\n",
            "Epoch 22/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8618 - loss: 0.0995 - precision_1: 0.9027 - recall_1: 0.9173 - val_accuracy: 0.8683 - val_loss: 0.0954 - val_precision_1: 0.8973 - val_recall_1: 0.9307\n",
            "Epoch 23/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8596 - loss: 0.1051 - precision_1: 0.8928 - recall_1: 0.9231 - val_accuracy: 0.8615 - val_loss: 0.0970 - val_precision_1: 0.9014 - val_recall_1: 0.9153\n",
            "Epoch 24/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8584 - loss: 0.1001 - precision_1: 0.8956 - recall_1: 0.9193 - val_accuracy: 0.8644 - val_loss: 0.0966 - val_precision_1: 0.8853 - val_recall_1: 0.9409\n",
            "Epoch 25/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8599 - loss: 0.1022 - precision_1: 0.8935 - recall_1: 0.9217 - val_accuracy: 0.8587 - val_loss: 0.0980 - val_precision_1: 0.9317 - val_recall_1: 0.8755\n",
            "Epoch 26/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8613 - loss: 0.1013 - precision_1: 0.9027 - recall_1: 0.9150 - val_accuracy: 0.8567 - val_loss: 0.0982 - val_precision_1: 0.8777 - val_recall_1: 0.9397\n",
            "Epoch 27/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8619 - loss: 0.1016 - precision_1: 0.8960 - recall_1: 0.9214 - val_accuracy: 0.8625 - val_loss: 0.0959 - val_precision_1: 0.8926 - val_recall_1: 0.9281\n",
            "Epoch 28/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8631 - loss: 0.0994 - precision_1: 0.8974 - recall_1: 0.9191 - val_accuracy: 0.8673 - val_loss: 0.0952 - val_precision_1: 0.8913 - val_recall_1: 0.9371\n",
            "Epoch 29/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8799 - loss: 0.0930 - precision_1: 0.9088 - recall_1: 0.9345 - val_accuracy: 0.8644 - val_loss: 0.0968 - val_precision_1: 0.8853 - val_recall_1: 0.9409\n",
            "Epoch 30/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8711 - loss: 0.0957 - precision_1: 0.8995 - recall_1: 0.9337 - val_accuracy: 0.8587 - val_loss: 0.0942 - val_precision_1: 0.9125 - val_recall_1: 0.8973\n",
            "Epoch 31/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8583 - loss: 0.1033 - precision_1: 0.8899 - recall_1: 0.9252 - val_accuracy: 0.8692 - val_loss: 0.0947 - val_precision_1: 0.9192 - val_recall_1: 0.9050\n",
            "Epoch 32/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8608 - loss: 0.1000 - precision_1: 0.8997 - recall_1: 0.9175 - val_accuracy: 0.8606 - val_loss: 0.0953 - val_precision_1: 0.8943 - val_recall_1: 0.9230\n",
            "Epoch 33/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8678 - loss: 0.1008 - precision_1: 0.8951 - recall_1: 0.9346 - val_accuracy: 0.8615 - val_loss: 0.0938 - val_precision_1: 0.9107 - val_recall_1: 0.9037\n",
            "Epoch 34/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8730 - loss: 0.0944 - precision_1: 0.9107 - recall_1: 0.9208 - val_accuracy: 0.8635 - val_loss: 0.0978 - val_precision_1: 0.9006 - val_recall_1: 0.9191\n",
            "Epoch 35/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8631 - loss: 0.0997 - precision_1: 0.9034 - recall_1: 0.9170 - val_accuracy: 0.8577 - val_loss: 0.0950 - val_precision_1: 0.9029 - val_recall_1: 0.9076\n",
            "Epoch 36/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8653 - loss: 0.1006 - precision_1: 0.9006 - recall_1: 0.9227 - val_accuracy: 0.8596 - val_loss: 0.0953 - val_precision_1: 0.9084 - val_recall_1: 0.9037\n",
            "Epoch 37/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8676 - loss: 0.0971 - precision_1: 0.9056 - recall_1: 0.9167 - val_accuracy: 0.8558 - val_loss: 0.0995 - val_precision_1: 0.8812 - val_recall_1: 0.9332\n",
            "Epoch 38/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8604 - loss: 0.1016 - precision_1: 0.8961 - recall_1: 0.9208 - val_accuracy: 0.8587 - val_loss: 0.1030 - val_precision_1: 0.9426 - val_recall_1: 0.8639\n",
            "Epoch 39/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8653 - loss: 0.0962 - precision_1: 0.9050 - recall_1: 0.9195 - val_accuracy: 0.8587 - val_loss: 0.0955 - val_precision_1: 0.9147 - val_recall_1: 0.8947\n",
            "Epoch 40/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8687 - loss: 0.0987 - precision_1: 0.9045 - recall_1: 0.9213 - val_accuracy: 0.8606 - val_loss: 0.0962 - val_precision_1: 0.9227 - val_recall_1: 0.8883\n",
            "Epoch 41/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8655 - loss: 0.0984 - precision_1: 0.9013 - recall_1: 0.9222 - val_accuracy: 0.8606 - val_loss: 0.0945 - val_precision_1: 0.9182 - val_recall_1: 0.8935\n",
            "Epoch 42/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8663 - loss: 0.0976 - precision_1: 0.8982 - recall_1: 0.9271 - val_accuracy: 0.8577 - val_loss: 0.1026 - val_precision_1: 0.8681 - val_recall_1: 0.9551\n",
            "Epoch 43/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8564 - loss: 0.1040 - precision_1: 0.8859 - recall_1: 0.9301 - val_accuracy: 0.8673 - val_loss: 0.0950 - val_precision_1: 0.9104 - val_recall_1: 0.9127\n",
            "Epoch 44/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8701 - loss: 0.0964 - precision_1: 0.9070 - recall_1: 0.9232 - val_accuracy: 0.8635 - val_loss: 0.0942 - val_precision_1: 0.9006 - val_recall_1: 0.9191\n",
            "Epoch 45/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8589 - loss: 0.1023 - precision_1: 0.8954 - recall_1: 0.9208 - val_accuracy: 0.8625 - val_loss: 0.0959 - val_precision_1: 0.8878 - val_recall_1: 0.9345\n",
            "Epoch 46/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8731 - loss: 0.0952 - precision_1: 0.9081 - recall_1: 0.9254 - val_accuracy: 0.8663 - val_loss: 0.0951 - val_precision_1: 0.9199 - val_recall_1: 0.8999\n",
            "Epoch 47/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8602 - loss: 0.1010 - precision_1: 0.8970 - recall_1: 0.9181 - val_accuracy: 0.8567 - val_loss: 0.0942 - val_precision_1: 0.9156 - val_recall_1: 0.8909\n",
            "Epoch 48/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8663 - loss: 0.0976 - precision_1: 0.9045 - recall_1: 0.9183 - val_accuracy: 0.8606 - val_loss: 0.0971 - val_precision_1: 0.8819 - val_recall_1: 0.9397\n",
            "Epoch 49/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8778 - loss: 0.0915 - precision_1: 0.9103 - recall_1: 0.9320 - val_accuracy: 0.8635 - val_loss: 0.0941 - val_precision_1: 0.8927 - val_recall_1: 0.9294\n",
            "Epoch 50/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8724 - loss: 0.0930 - precision_1: 0.9053 - recall_1: 0.9270 - val_accuracy: 0.8548 - val_loss: 0.1009 - val_precision_1: 0.8765 - val_recall_1: 0.9384\n",
            "Epoch 51/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8666 - loss: 0.0985 - precision_1: 0.9015 - recall_1: 0.9271 - val_accuracy: 0.8635 - val_loss: 0.0937 - val_precision_1: 0.9110 - val_recall_1: 0.9063\n",
            "Epoch 52/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8658 - loss: 0.0974 - precision_1: 0.9016 - recall_1: 0.9224 - val_accuracy: 0.8663 - val_loss: 0.0934 - val_precision_1: 0.9082 - val_recall_1: 0.9140\n",
            "Epoch 53/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8669 - loss: 0.0975 - precision_1: 0.9039 - recall_1: 0.9201 - val_accuracy: 0.8644 - val_loss: 0.1000 - val_precision_1: 0.8780 - val_recall_1: 0.9512\n",
            "Epoch 54/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8651 - loss: 0.0956 - precision_1: 0.9032 - recall_1: 0.9202 - val_accuracy: 0.8529 - val_loss: 0.1017 - val_precision_1: 0.9433 - val_recall_1: 0.8549\n",
            "Epoch 55/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8673 - loss: 0.0977 - precision_1: 0.9061 - recall_1: 0.9172 - val_accuracy: 0.8587 - val_loss: 0.0942 - val_precision_1: 0.9083 - val_recall_1: 0.9024\n",
            "Epoch 56/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8690 - loss: 0.0958 - precision_1: 0.9066 - recall_1: 0.9200 - val_accuracy: 0.8615 - val_loss: 0.0943 - val_precision_1: 0.9014 - val_recall_1: 0.9153\n",
            "Epoch 57/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8736 - loss: 0.0937 - precision_1: 0.9041 - recall_1: 0.9320 - val_accuracy: 0.8606 - val_loss: 0.0957 - val_precision_1: 0.9238 - val_recall_1: 0.8870\n",
            "Epoch 58/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8760 - loss: 0.0923 - precision_1: 0.9132 - recall_1: 0.9264 - val_accuracy: 0.8567 - val_loss: 0.0948 - val_precision_1: 0.8928 - val_recall_1: 0.9191\n",
            "Epoch 59/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8656 - loss: 0.0979 - precision_1: 0.9009 - recall_1: 0.9260 - val_accuracy: 0.8635 - val_loss: 0.0954 - val_precision_1: 0.8986 - val_recall_1: 0.9217\n",
            "Epoch 60/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8669 - loss: 0.0983 - precision_1: 0.8996 - recall_1: 0.9261 - val_accuracy: 0.8644 - val_loss: 0.0946 - val_precision_1: 0.8988 - val_recall_1: 0.9230\n",
            "Epoch 61/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8776 - loss: 0.0901 - precision_1: 0.9124 - recall_1: 0.9284 - val_accuracy: 0.8615 - val_loss: 0.0935 - val_precision_1: 0.9216 - val_recall_1: 0.8909\n",
            "Epoch 62/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8683 - loss: 0.0970 - precision_1: 0.9018 - recall_1: 0.9281 - val_accuracy: 0.8663 - val_loss: 0.0940 - val_precision_1: 0.9178 - val_recall_1: 0.9024\n",
            "Epoch 63/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8669 - loss: 0.0962 - precision_1: 0.8994 - recall_1: 0.9274 - val_accuracy: 0.8625 - val_loss: 0.0972 - val_precision_1: 0.8795 - val_recall_1: 0.9461\n",
            "Epoch 64/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8670 - loss: 0.0942 - precision_1: 0.9034 - recall_1: 0.9221 - val_accuracy: 0.8625 - val_loss: 0.0944 - val_precision_1: 0.9218 - val_recall_1: 0.8922\n",
            "Epoch 65/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8745 - loss: 0.0936 - precision_1: 0.9093 - recall_1: 0.9254 - val_accuracy: 0.8625 - val_loss: 0.0958 - val_precision_1: 0.9263 - val_recall_1: 0.8870\n",
            "Epoch 66/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8660 - loss: 0.0968 - precision_1: 0.9124 - recall_1: 0.9097 - val_accuracy: 0.8529 - val_loss: 0.0977 - val_precision_1: 0.8762 - val_recall_1: 0.9358\n",
            "Epoch 67/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8681 - loss: 0.0979 - precision_1: 0.8999 - recall_1: 0.9249 - val_accuracy: 0.8625 - val_loss: 0.0931 - val_precision_1: 0.9087 - val_recall_1: 0.9076\n",
            "Epoch 68/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8704 - loss: 0.0962 - precision_1: 0.9060 - recall_1: 0.9226 - val_accuracy: 0.8548 - val_loss: 0.0986 - val_precision_1: 0.8829 - val_recall_1: 0.9294\n",
            "Epoch 69/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8624 - loss: 0.0998 - precision_1: 0.8949 - recall_1: 0.9263 - val_accuracy: 0.8673 - val_loss: 0.0942 - val_precision_1: 0.9125 - val_recall_1: 0.9101\n",
            "Epoch 70/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8653 - loss: 0.0981 - precision_1: 0.9050 - recall_1: 0.9176 - val_accuracy: 0.8644 - val_loss: 0.0940 - val_precision_1: 0.8988 - val_recall_1: 0.9230\n",
            "Epoch 71/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8808 - loss: 0.0926 - precision_1: 0.9111 - recall_1: 0.9330 - val_accuracy: 0.8548 - val_loss: 0.0993 - val_precision_1: 0.9373 - val_recall_1: 0.8639\n",
            "Epoch 72/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8703 - loss: 0.0937 - precision_1: 0.9150 - recall_1: 0.9165 - val_accuracy: 0.8452 - val_loss: 0.1061 - val_precision_1: 0.9465 - val_recall_1: 0.8408\n",
            "Epoch 73/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8628 - loss: 0.0975 - precision_1: 0.9066 - recall_1: 0.9144 - val_accuracy: 0.8673 - val_loss: 0.0935 - val_precision_1: 0.9093 - val_recall_1: 0.9140\n",
            "Epoch 74/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8686 - loss: 0.0965 - precision_1: 0.8999 - recall_1: 0.9299 - val_accuracy: 0.8644 - val_loss: 0.0958 - val_precision_1: 0.9220 - val_recall_1: 0.8947\n",
            "Epoch 75/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8737 - loss: 0.0935 - precision_1: 0.9081 - recall_1: 0.9243 - val_accuracy: 0.8644 - val_loss: 0.0951 - val_precision_1: 0.8929 - val_recall_1: 0.9307\n",
            "Epoch 76/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8716 - loss: 0.0963 - precision_1: 0.8992 - recall_1: 0.9332 - val_accuracy: 0.8644 - val_loss: 0.0935 - val_precision_1: 0.9090 - val_recall_1: 0.9101\n",
            "Epoch 77/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8659 - loss: 0.0986 - precision_1: 0.8993 - recall_1: 0.9255 - val_accuracy: 0.8596 - val_loss: 0.0957 - val_precision_1: 0.8874 - val_recall_1: 0.9307\n",
            "Epoch 78/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8688 - loss: 0.0964 - precision_1: 0.9025 - recall_1: 0.9258 - val_accuracy: 0.8654 - val_loss: 0.0953 - val_precision_1: 0.9243 - val_recall_1: 0.8935\n",
            "Epoch 79/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8680 - loss: 0.0962 - precision_1: 0.9043 - recall_1: 0.9247 - val_accuracy: 0.8615 - val_loss: 0.0968 - val_precision_1: 0.8915 - val_recall_1: 0.9281\n",
            "Epoch 80/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8591 - loss: 0.1001 - precision_1: 0.8928 - recall_1: 0.9265 - val_accuracy: 0.8615 - val_loss: 0.0987 - val_precision_1: 0.9320 - val_recall_1: 0.8793\n",
            "Epoch 81/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8765 - loss: 0.0907 - precision_1: 0.9129 - recall_1: 0.9276 - val_accuracy: 0.8558 - val_loss: 0.0958 - val_precision_1: 0.9079 - val_recall_1: 0.8986\n",
            "Epoch 82/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8711 - loss: 0.0941 - precision_1: 0.9044 - recall_1: 0.9271 - val_accuracy: 0.8644 - val_loss: 0.0939 - val_precision_1: 0.9121 - val_recall_1: 0.9063\n",
            "Epoch 83/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8694 - loss: 0.0946 - precision_1: 0.9055 - recall_1: 0.9255 - val_accuracy: 0.8587 - val_loss: 0.0961 - val_precision_1: 0.9202 - val_recall_1: 0.8883\n",
            "Epoch 84/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8654 - loss: 0.0996 - precision_1: 0.9054 - recall_1: 0.9158 - val_accuracy: 0.8625 - val_loss: 0.0954 - val_precision_1: 0.9195 - val_recall_1: 0.8947\n",
            "Epoch 85/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8691 - loss: 0.0989 - precision_1: 0.9078 - recall_1: 0.9184 - val_accuracy: 0.8625 - val_loss: 0.0978 - val_precision_1: 0.9274 - val_recall_1: 0.8858\n",
            "Epoch 86/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8746 - loss: 0.0931 - precision_1: 0.9107 - recall_1: 0.9268 - val_accuracy: 0.8644 - val_loss: 0.0943 - val_precision_1: 0.9111 - val_recall_1: 0.9076\n",
            "Epoch 87/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8813 - loss: 0.0900 - precision_1: 0.9144 - recall_1: 0.9320 - val_accuracy: 0.8596 - val_loss: 0.0948 - val_precision_1: 0.9022 - val_recall_1: 0.9114\n",
            "Epoch 88/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8742 - loss: 0.0923 - precision_1: 0.9108 - recall_1: 0.9255 - val_accuracy: 0.8644 - val_loss: 0.0936 - val_precision_1: 0.9143 - val_recall_1: 0.9037\n",
            "Epoch 89/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8714 - loss: 0.0972 - precision_1: 0.9053 - recall_1: 0.9242 - val_accuracy: 0.8663 - val_loss: 0.0940 - val_precision_1: 0.9113 - val_recall_1: 0.9101\n",
            "Epoch 90/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8765 - loss: 0.0950 - precision_1: 0.9067 - recall_1: 0.9322 - val_accuracy: 0.8654 - val_loss: 0.0941 - val_precision_1: 0.9091 - val_recall_1: 0.9114\n",
            "Epoch 91/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8629 - loss: 0.0984 - precision_1: 0.8950 - recall_1: 0.9248 - val_accuracy: 0.8635 - val_loss: 0.0950 - val_precision_1: 0.9207 - val_recall_1: 0.8947\n",
            "Epoch 92/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8652 - loss: 0.0966 - precision_1: 0.9000 - recall_1: 0.9236 - val_accuracy: 0.8567 - val_loss: 0.0966 - val_precision_1: 0.8860 - val_recall_1: 0.9281\n",
            "Epoch 93/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8661 - loss: 0.0956 - precision_1: 0.9027 - recall_1: 0.9236 - val_accuracy: 0.8567 - val_loss: 0.0976 - val_precision_1: 0.8987 - val_recall_1: 0.9114\n",
            "Epoch 94/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8720 - loss: 0.0948 - precision_1: 0.9084 - recall_1: 0.9238 - val_accuracy: 0.8654 - val_loss: 0.0956 - val_precision_1: 0.8989 - val_recall_1: 0.9243\n",
            "Epoch 95/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8737 - loss: 0.0956 - precision_1: 0.8980 - recall_1: 0.9395 - val_accuracy: 0.8615 - val_loss: 0.0939 - val_precision_1: 0.9107 - val_recall_1: 0.9037\n",
            "Epoch 96/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8669 - loss: 0.0949 - precision_1: 0.9057 - recall_1: 0.9182 - val_accuracy: 0.8606 - val_loss: 0.0987 - val_precision_1: 0.8801 - val_recall_1: 0.9422\n",
            "Epoch 97/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8663 - loss: 0.0961 - precision_1: 0.9018 - recall_1: 0.9229 - val_accuracy: 0.8615 - val_loss: 0.0944 - val_precision_1: 0.9205 - val_recall_1: 0.8922\n",
            "Epoch 98/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8581 - loss: 0.0992 - precision_1: 0.8951 - recall_1: 0.9215 - val_accuracy: 0.8663 - val_loss: 0.0937 - val_precision_1: 0.9061 - val_recall_1: 0.9166\n",
            "Epoch 99/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8740 - loss: 0.0956 - precision_1: 0.9086 - recall_1: 0.9254 - val_accuracy: 0.8654 - val_loss: 0.0951 - val_precision_1: 0.8989 - val_recall_1: 0.9243\n",
            "Epoch 100/100\n",
            "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8665 - loss: 0.0941 - precision_1: 0.9035 - recall_1: 0.9242 - val_accuracy: 0.8529 - val_loss: 0.0963 - val_precision_1: 0.9023 - val_recall_1: 0.9012\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x2606888ed10>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 필요 라이브러리 import\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# ModelCheckpoint 콜백 생성\n",
        "checkpoint = ModelCheckpoint('best_model_wine.keras', save_best_only=True, monitor='val_loss', mode='min')\n",
        "\n",
        "# 모델 생성\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(train_data.shape[1], )),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['accuracy', Precision(), Recall()])\n",
        "\n",
        "# 모델 학습\n",
        "model.fit(train_data, train_target, epochs=100, batch_size=20,\n",
        "          validation_split=0.2,callbacks=[checkpoint])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6F6G9YAJfYU",
        "outputId": "b197a92e-3060-45e2-f8ba-cfd150cfcf8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.67      0.71       320\n",
            "           1       0.90      0.93      0.91       980\n",
            "\n",
            "    accuracy                           0.86      1300\n",
            "   macro avg       0.82      0.80      0.81      1300\n",
            "weighted avg       0.86      0.86      0.86      1300\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# 예측확률을 0, 1값으로 변환\n",
        "predicted = model.predict(test_data)\n",
        "predicted_labels = (predicted > 0.5).astype(int)\n",
        "\n",
        "# classification_report 출력\n",
        "report = classification_report(test_target, predicted_labels)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkKRonm3JpOk",
        "outputId": "ad4ee8db-eb06-4a40-a83e-872110e9b41a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsAAAAIjCAYAAAAN/63DAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAz00lEQVR4nO3deXxM9/7H8fckGJE9RGNNQqzXThdtibTW2pdaW0L1UtS+twhKSu2K0CqxtVRLlbZKU9xo3asqtqIE1dpFLRESZH5/+Jl7p6FNKsng+3o+Hnk8zDnfOfM5eTyavhxnJhabzWYTAAAAYAgXZw8AAAAAZCcCGAAAAEYhgAEAAGAUAhgAAABGIYABAABgFAIYAAAARiGAAQAAYBQCGAAAAEYhgAEAAGAUAhgAssmhQ4dUt25deXt7y2KxaPXq1Zl6/GPHjslisWjhwoWZetyHWa1atVSrVi1njwHgAUMAAzBKfHy8unXrpmLFiil37tzy8vLSM888o+nTp+vatWtZ+tqdOnXSnj17NG7cOC1evFjVqlXL0tfLTuHh4bJYLPLy8rrr9/HQoUOyWCyyWCyaNGlSho9/8uRJRUREKC4uLhOmBWC6HM4eAACyy7p16/Tiiy/KarWqY8eOKleunFJSUhQbG6tBgwZp3759mjdvXpa89rVr1/T999/rjTfeUK9evbLkNQIDA3Xt2jXlzJkzS47/V3LkyKGkpCR9/vnnat26tcO+pUuXKnfu3Lp+/frfOvbJkyc1evRoBQUFqVKlSul+3tdff/23Xg/Ao40ABmCEo0ePqm3btgoMDFRMTIwKFChg39ezZ08dPnxY69aty7LXP3funCTJx8cny17DYrEod+7cWXb8v2K1WvXMM8/oww8/TBPAy5YtU8OGDfXJJ59kyyxJSUnKkyePcuXKlS2vB+Dhwi0QAIwwceJEJSYmav78+Q7xe0dISIj69Oljf3zz5k2NHTtWxYsXl9VqVVBQkIYPH67k5GSH5wUFBalRo0aKjY3VE088ody5c6tYsWJatGiRfU1ERIQCAwMlSYMGDZLFYlFQUJCk27cO3Pnz/4qIiJDFYnHYtmHDBj377LPy8fGRh4eHSpUqpeHDh9v33+se4JiYGNWoUUPu7u7y8fFR06ZNtX///ru+3uHDhxUeHi4fHx95e3urc+fOSkpKuvc39g/at2+vL7/8UhcvXrRv2759uw4dOqT27dunWX/hwgUNHDhQ5cuXl4eHh7y8vNSgQQPt2rXLvmbTpk16/PHHJUmdO3e230px5zxr1aqlcuXKaceOHapZs6by5Mlj/7788R7gTp06KXfu3GnOv169evL19dXJkyfTfa4AHl4EMAAjfP755ypWrJiefvrpdK3v2rWrRo4cqSpVqmjq1KkKDQ1VZGSk2rZtm2bt4cOH1apVK9WpU0eTJ0+Wr6+vwsPDtW/fPklSixYtNHXqVElSu3bttHjxYk2bNi1D8+/bt0+NGjVScnKyxowZo8mTJ6tJkybaunXrnz5v48aNqlevns6ePauIiAj1799f3333nZ555hkdO3YszfrWrVvrypUrioyMVOvWrbVw4UKNHj063XO2aNFCFotFn376qX3bsmXLVLp0aVWpUiXN+iNHjmj16tVq1KiRpkyZokGDBmnPnj0KDQ21x2iZMmU0ZswYSdI///lPLV68WIsXL1bNmjXtx0lISFCDBg1UqVIlTZs2TWFhYXedb/r06fL391enTp1069YtSdLcuXP19ddfa+bMmSpYsGC6zxXAQ8wGAI+4S5cu2STZmjZtmq71cXFxNkm2rl27OmwfOHCgTZItJibGvi0wMNAmybZlyxb7trNnz9qsVqttwIAB9m1Hjx61SbK98847Dsfs1KmTLTAwMM0Mo0aNsv3vj+ipU6faJNnOnTt3z7nvvMaCBQvs2ypVqmTLnz+/LSEhwb5t165dNhcXF1vHjh3TvF6XLl0cjtm8eXNb3rx57/ma/3se7u7uNpvNZmvVqpXt+eeft9lsNtutW7dsAQEBttGjR9/1e3D9+nXbrVu30pyH1Wq1jRkzxr5t+/btac7tjtDQUJskW1RU1F33hYaGOmxbv369TZLtrbfesh05csTm4eFha9as2V+eI4BHB1eAATzyLl++LEny9PRM1/ovvvhCktS/f3+H7QMGDJCkNPcKly1bVjVq1LA/9vf3V6lSpXTkyJG/PfMf3bl3+LPPPlNqamq6nnPq1CnFxcUpPDxcfn5+9u0VKlRQnTp17Of5v7p37+7wuEaNGkpISLB/D9Ojffv22rRpk06fPq2YmBidPn36rrc/SLfvG3Zxuf2/olu3bikhIcF+e8ePP/6Y7te0Wq3q3LlzutbWrVtX3bp105gxY9SiRQvlzp1bc+fOTfdrAXj4EcAAHnleXl6SpCtXrqRr/S+//CIXFxeFhIQ4bA8ICJCPj49++eUXh+1FixZNcwxfX1/9/vvvf3PitNq0aaNnnnlGXbt21WOPPaa2bdtqxYoVfxrDd+YsVapUmn1lypTR+fPndfXqVYftfzwXX19fScrQubzwwgvy9PTU8uXLtXTpUj3++ONpvpd3pKamaurUqSpRooSsVqvy5csnf39/7d69W5cuXUr3axYqVChDb3ibNGmS/Pz8FBcXpxkzZih//vzpfi6Ahx8BDOCR5+XlpYIFC2rv3r0Zet4f34R2L66urnfdbrPZ/vZr3Lk/9Q43Nzdt2bJFGzdu1Msvv6zdu3erTZs2qlOnTpq19+N+zuUOq9WqFi1aKDo6WqtWrbrn1V9JGj9+vPr376+aNWtqyZIlWr9+vTZs2KB//OMf6b7SLd3+/mTEzp07dfbsWUnSnj17MvRcAA8/AhiAERo1aqT4+Hh9//33f7k2MDBQqampOnTokMP2M2fO6OLFi/ZPdMgMvr6+Dp+YcMcfrzJLkouLi55//nlNmTJFP/30k8aNG6eYmBh9++23dz32nTkPHjyYZt+BAweUL18+ubu7398J3EP79u21c+dOXbly5a5vHLxj5cqVCgsL0/z589W2bVvVrVtXtWvXTvM9Se9fRtLj6tWr6ty5s8qWLat//vOfmjhxorZv355pxwfw4COAARhh8ODBcnd3V9euXXXmzJk0++Pj4zV9+nRJt/8JX1KaT2qYMmWKJKlhw4aZNlfx4sV16dIl7d69277t1KlTWrVqlcO6CxcupHnunV8I8cePZrujQIECqlSpkqKjox2Ccu/evfr666/t55kVwsLCNHbsWL377rsKCAi45zpXV9c0V5c//vhjnThxwmHbnVC/218WMmrIkCE6fvy4oqOjNWXKFAUFBalTp073/D4CePTwizAAGKF48eJatmyZ2rRpozJlyjj8JrjvvvtOH3/8scLDwyVJFStWVKdOnTRv3jxdvHhRoaGh+s9//qPo6Gg1a9bsnh+x9Xe0bdtWQ4YMUfPmzdW7d28lJSVpzpw5KlmypMObwMaMGaMtW7aoYcOGCgwM1NmzZzV79mwVLlxYzz777D2P/84776hBgwaqXr26XnnlFV27dk0zZ86Ut7e3IiIiMu08/sjFxUVvvvnmX65r1KiRxowZo86dO+vpp5/Wnj17tHTpUhUrVsxhXfHixeXj46OoqCh5enrK3d1dTz75pIKDgzM0V0xMjGbPnq1Ro0bZP5ZtwYIFqlWrlkaMGKGJEydm6HgAHk5cAQZgjCZNmmj37t1q1aqVPvvsM/Xs2VNDhw7VsWPHNHnyZM2YMcO+9v3339fo0aO1fft29e3bVzExMRo2bJg++uijTJ0pb968WrVqlfLkyaPBgwcrOjpakZGRaty4cZrZixYtqg8++EA9e/bUrFmzVLNmTcXExMjb2/uex69du7a++uor5c2bVyNHjtSkSZP01FNPaevWrRmOx6wwfPhwDRgwQOvXr1efPn30448/at26dSpSpIjDupw5cyo6Olqurq7q3r272rVrp82bN2fota5cuaIuXbqocuXKeuONN+zba9SooT59+mjy5Mnatm1bppwXgAebxZaRdzYAAAAADzmuAAMAAMAoBDAAAACMQgADAADAKAQwAAAAjEIAAwAAwCgEMAAAAIxCAAMAAMAo/Ca4dNp/8qqzRwCATFXAN7ezRwCATOXj5pqudVwBBgAAgFEIYAAAABiFAAYAAIBRCGAAAAAYhQAGAACAUQhgAAAAGIUABgAAgFEIYAAAABiFAAYAAIBRCGAAAAAYhQAGAACAUQhgAAAAGIUABgAAgFEIYAAAABiFAAYAAIBRCGAAAAAYhQAGAACAUQhgAAAAGIUABgAAgFEIYAAAABiFAAYAAIBRCGAAAAAYhQAGAACAUQhgAAAAGIUABgAAgFEIYAAAABiFAAYAAIBRCGAAAAAYhQAGAACAUQhgAAAAGIUABgAAgFEIYAAAABiFAAYAAIBRCGAAAAAYhQAGAACAUQhgAAAAGIUABgAAgFEIYAAAABiFAAYAAIBRCGAAAAAYhQAGAACAUQhgAAAAGIUABgAAgFEIYAAAABiFAAYAAIBRCGAAAAAYhQAGAACAUQhgAAAAGIUABgAAgFEIYAAAABiFAAYAAIBRCGAAAAAYhQAGAACAUQhgAAAAGIUABgAAgFEIYAAAABiFAAYAAIBRCGAAAAAYhQAGAACAUQhgAAAAGIUABgAAgFEIYAAAABiFAAYAAIBRCGAAAAAYhQAGAACAUQhgAAAAGIUABgAAgFEIYAAAABiFAAYAAIBRCGAAAAAYhQAGAACAUQhgAAAAGIUABgAAgFEIYAAAABiFAAYAAIBRCGAAAAAYhQAGAACAUQhgAAAAGIUABgAAgFEIYAAAABiFAAYAAIBRCGAAAAAYhQAGAACAUQhgAAAAGIUABgAAgFEIYAAAABiFAAYAAIBRCGAAAAAYhQAGAACAUQhgAAAAGIUABgAAgFEIYAAAABiFAAYAAIBRCGAAAAAYhQAGAACAUQhgAAAAGIUABgAAgFEIYAAAABiFAAYAAIBRCGAAAAAYhQAGAACAUQhgAAAAGIUABgAAgFEIYAAAABiFAAYAAIBRCGAAAAAYhQAGAACAUQhgAAAAGIUABgAAgFEeqAC2WCx/+hUREeHsEYEMW7n0Aw3s/pLavvCsOjV/XuPf7K8Tx485rFn/+Sd6o++ratewhpqFVVFi4pV7Hu9GSor6dm2rZmFVdOTwwSyeHgDS2rnjBw3o3UMN64TqyUpltTlmo8N+m82mubNn6oXaNVXzycrq1a2Ljv9yLM1xYrdsVpeX2qjmk5VVu8ZTGtS3VzadAUz3QAXwqVOn7F/Tpk2Tl5eXw7aBAwfa19psNt28edOJ0wLps2/XDjVo1loTZ0Ur4p05unXzpiIG99D1a9fsa5KTr6vKE0+rVYcuf3m86LnT5ZfPPytHBoA/de1akkqULKVBw0bcdf/ihfO1YtkSDXljlOYv/ki53dzUp8c/lZycbF8Ts/FrjX5ziBo1ba4lK1Zp3sIlqtegYXadAgz3QAVwQECA/cvb21sWi8X++MCBA/L09NSXX36pqlWrymq1KjY2VuHh4WrWrJnDcfr27atatWrZH6empioyMlLBwcFyc3NTxYoVtXLlyuw9ORhr1MRZer5+ExUNLq7gkJLqPXS0zp05rfiff7KvadKqg1q276ySZcv/6bF2/Hur4n74Xp2798vqsQHgnp5+tqa69+qjWs/VTrPPZrPpo6WL1PnVbgoNe14lSpZSxNi3df7cWW3+9htJ0s2bNzVlYqRe7zdILV5sq6KBQSpWPES16zXI7lOBoXI4e4CMGjp0qCZNmqRixYrJ19c3Xc+JjIzUkiVLFBUVpRIlSmjLli166aWX5O/vr9DQ0CyeGHCUdPX27Q0eXt4Zet7FCwmaPWmshr01Rbly586K0QDgvp088ZsSzp/XE09Wt2/z8PTUP8pX0J5dcapb/wUd3P+Tzp09I4vFopfbtFBCwnmVLFVar/cbpOIhJZw4PUzx0AXwmDFjVKdOnXSvT05O1vjx47Vx40ZVr377P8ZixYopNjZWc+fOvWsAJycnO/wzjSSlJN9ULqv1/oaH8VJTUzX/3UkqU66SAoND0v08m82mGRNGqV6TVgopVVZnTp/MwikB4O9LOH9ekuSXN5/Ddj+/vLqQcHvfiRO/SZLenztLfQYMUYGChbRs0UK91rWTPv7sC3l7+2TrzDDPA3ULRHpUq1YtQ+sPHz6spKQk1alTRx4eHvavRYsWKT4+/q7PiYyMlLe3t8PXvHcnZcb4MNy86W/rl6PxGjAyMkPPW/fpR7qWlKSW7Ttn0WQAkH1sqamSpPBXuum52nVVpuw/NGLMOFksFn2zYb2Tp4MJHrorwO7u7g6PXVxcZLPZHLbduHHD/ufExERJ0rp161SoUCGHddZ7XNEdNmyY+vfv77DtaAJvuMP9mTf9bW3//l8aP/195fN/LEPP3b1zuw7+tFsv1n3KYfvAbi8ptHYD9Rk2JjNHBYC/LW++21d+LyScVz7//75h98KFBJUoWfr2mv/fHly8uH1/rly5VKhQYZ05dSobp4WpHroA/iN/f3/t3bvXYVtcXJxy5swpSSpbtqysVquOHz+e7vt9rVZrmjjOlXg1cwaGcWw2m96bMUHbYr/VW1Pf02MFCv31k/7g1dcHqcMrPeyPL5w/p9GDe2rgyLdVsmy5zBwXAO5LwUKFlTdfPm3/zzaVLF1G0u2LUfv27FaLF9tKkkqX+Ydy5cql48eOqVLlqpKkmzdu6OTJkwooUNBps8McD30AP/fcc3rnnXe0aNEiVa9eXUuWLNHevXtVuXJlSZKnp6cGDhyofv36KTU1Vc8++6wuXbqkrVu3ysvLS506dXLyGeBRN3fa29ryzZca/tZUueXJo98v3L4HLo+7h6zW229m+/3Cef1+IUGnT/wqSfrlyCG55XGXf/4AeXp5y/+xAg7HzO2WR5IUUKhwhq8mA8D9Skq6qt+OH7c/PnnihH4+sF9e3t4KKFBQbTt01IL35qpI0UAVLFRYc2fNUD7//AoNe16S5OHhoeat2mjenHeV/7EAFShYUEuiP5AkPV+3nlPOCWZ56AO4Xr16GjFihAYPHqzr16+rS5cu6tixo/bs2WNfM3bsWPn7+ysyMlJHjhyRj4+PqlSpouHDhztxcpjiqzUfS5Le7Peqw/bXh0To+fpN/n/NSi2Pnmff90afrmnWAMCDYv++ferxarj98bTJEyRJDRs308ix4/Vy+Cu6du2aIseOUuKVK6pYuYqmz57n8K+rvfsNlGsOV0W8OVTJyddVrlwFzZ73gbwy+Ak5wN9hsf3xBlrc1f6T3AIB4NFSwJeP0wPwaPFxc03XuofuUyAAAACA+0EAAwAAwCgEMAAAAIxCAAMAAMAoBDAAAACMQgADAADAKAQwAAAAjEIAAwAAwCgEMAAAAIxCAAMAAMAoBDAAAACMQgADAADAKAQwAAAAjEIAAwAAwCgEMAAAAIxCAAMAAMAoBDAAAACMQgADAADAKAQwAAAAjEIAAwAAwCgEMAAAAIxCAAMAAMAoBDAAAACMQgADAADAKAQwAAAAjEIAAwAAwCgEMAAAAIxCAAMAAMAoBDAAAACMQgADAADAKAQwAAAAjEIAAwAAwCgEMAAAAIxCAAMAAMAoBDAAAACMQgADAADAKAQwAAAAjEIAAwAAwCgEMAAAAIxCAAMAAMAoBDAAAACMQgADAADAKAQwAAAAjEIAAwAAwCgEMAAAAIxCAAMAAMAoBDAAAACMQgADAADAKAQwAAAAjEIAAwAAwCgEMAAAAIxCAAMAAMAoBDAAAACMQgADAADAKAQwAAAAjEIAAwAAwCgEMAAAAIxCAAMAAMAoBDAAAACMQgADAADAKAQwAAAAjEIAAwAAwCgEMAAAAIxCAAMAAMAoBDAAAACMQgADAADAKAQwAAAAjEIAAwAAwCgEMAAAAIxCAAMAAMAoBDAAAACMQgADAADAKAQwAAAAjEIAAwAAwCgEMAAAAIxCAAMAAMAoBDAAAACMQgADAADAKAQwAAAAjEIAAwAAwCgEMAAAAIxCAAMAAMAoBDAAAACMQgADAADAKAQwAAAAjEIAAwAAwCgEMAAAAIxCAAMAAMAoBDAAAACMQgADAADAKAQwAAAAjJIjPYvWrFmT7gM2adLkbw8DAAAAZDWLzWaz/dUiF5f0XSi2WCy6devWfQ/1INp/8qqzRwCATFXAN7ezRwCATOXj5pqudem6ApyamnpfwwAAAAAPCu4BBgAAgFHSdQX4j65evarNmzfr+PHjSklJcdjXu3fvTBkMAAAAyArpugf4f+3cuVMvvPCCkpKSdPXqVfn5+en8+fPKkyeP8ufPryNHjmTVrE7FPcAAHjXcAwzgUZPee4AzfAtEv3791LhxY/3+++9yc3PTtm3b9Msvv6hq1aqaNGlShgcFAAAAslOGAzguLk4DBgyQi4uLXF1dlZycrCJFimjixIkaPnx4VswIAAAAZJoMB3DOnDntH4uWP39+HT9+XJLk7e2tX3/9NXOnAwAAADJZht8EV7lyZW3fvl0lSpRQaGioRo4cqfPnz2vx4sUqV65cVswIAAAAZJoMXwEeP368ChQoIEkaN26cfH199dprr+ncuXOaN29epg8IAAAAZKYMfwqEqfgUCACPGj4FAsCjJss+BQIAAAB4mGX4HuDg4GBZLJZ77n9UPwcYAAAAj4YMB3Dfvn0dHt+4cUM7d+7UV199pUGDBmXWXAAAAECWyHAA9+nT567bZ82apR9++OG+BwIAAACyUqa9Ce7IkSOqVKmSLl++nBmHe+DwJjgAjxreBAfgUZPtb4JbuXKl/Pz8MutwAAAAQJb4W78I43/fBGez2XT69GmdO3dOs2fPztThAAAAgMyW4QBu2rSpQwC7uLjI399ftWrVUunSpTN1uAdJcH53Z48AAJnK9/Fezh4BADLVtZ3vpmsdvwgjna7fdPYEAJC5CGAAj5r0BnCG7wF2dXXV2bNn02xPSEiQq2v6bjwGAAAAnCXDAXyvC8bJycnKlSvXfQ8EAAAAZKV03wM8Y8YMSZLFYtH7778vDw8P+75bt25py5Ytj/Q9wAAAAHg0pDuAp06dKun2FeCoqCiH2x1y5cqloKAgRUVFZf6EAAAAQCZKdwAfPXpUkhQWFqZPP/1Uvr6+WTYUAAAAkFUy/DFo3377bVbMAQAAAGSLDL8JrmXLlpowYUKa7RMnTtSLL76YKUMBAAAAWSXDAbxlyxa98MILabY3aNBAW7ZsyZShAAAAgKyS4QBOTEy868ed5cyZU5cvX86UoQAAAICskuEALl++vJYvX55m+0cffaSyZctmylAAAABAVsnwm+BGjBihFi1aKD4+Xs8995wk6ZtvvtGyZcu0cuXKTB8QAAAAyEwZDuDGjRtr9erVGj9+vFauXCk3NzdVrFhRMTEx8vPzy4oZAQAAgExjsd3rdxun0+XLl/Xhhx9q/vz52rFjh27dupVZsz1Qrt909gQAkLl8H+/l7BEAIFNd2/luutZl+B7gO7Zs2aJOnTqpYMGCmjx5sp577jlt27bt7x4OAAAAyBYZugXi9OnTWrhwoebPn6/Lly+rdevWSk5O1urVq3kDHAAAAB4K6b4C3LhxY5UqVUq7d+/WtGnTdPLkSc2cOTMrZwMAAAAyXbqvAH/55Zfq3bu3XnvtNZUoUSIrZwIAAACyTLqvAMfGxurKlSuqWrWqnnzySb377rs6f/58Vs4GAAAAZLp0B/BTTz2l9957T6dOnVK3bt300UcfqWDBgkpNTdWGDRt05cqVrJwTAAAAyBT39TFoBw8e1Pz587V48WJdvHhRderU0Zo1azJzvgcGH4MG4FHDx6ABeNRk+cegSVKpUqU0ceJE/fbbb/rwww/v51AAAABAtrjvX4RhCq4AA3jUcAUYwKMmW64AAwAAAA8bAhgAAABGIYABAABgFAIYAAAARiGAAQAAYBQCGAAAAEYhgAEAAGAUAhgAAABGIYABAABgFAIYAAAARiGAAQAAYBQCGAAAAEYhgAEAAGAUAhgAAABGIYABAABgFAIYAAAARiGAAQAAYBQCGAAAAEYhgAEAAGAUAhgAAABGIYABAABgFAIYAAAARiGAAQAAYBQCGAAAAEYhgAEAAGAUAhgAAABGIYABAABgFAIYAAAARiGAAQAAYBQCGAAAAEYhgAEAAGAUAhgAAABGIYABAABgFAIYAAAARiGAAQAAYBQCGAAAAEYhgAEAAGAUAhgAAABGIYABAABgFAIYAAAARiGAAQAAYBQCGAAAAEYhgAEAAGAUAhgAAABGIYABAABgFAIYAAAARiGAAQAAYBQCGAAAAEYhgAEAAGAUAhgAAABGIYABAABgFAIYAAAARiGAAQAAYBQCGAAAAEYhgAEAAGAUAhgAAABGIYABAABgFAIYAAAARiGAAQAAYBQCGAAAAEYhgAEAAGAUAhgAAABGIYABAABgFAIYAAAARiGAAQAAYBQCGAAAAEYhgAEAAGAUAhgAAABGIYABAABgFAIYAAAARiGAAQAAYBQCGAAAAEYhgAEAAGAUAhgAAABGIYABAABgFAIYAAAARiGAAQAAYBQCGAAAAEYhgAEAAGAUAhgAAABGIYABAABgFAIYAAAARiGAAQAAYBQCGAAAAEYhgAEAAGCUhzKAFy5cKB8fH2ePAQAAgIdQDme+eHh4uKKjo9NsP3TokEJCQpwwEZA9GtR5TidPnkizvU3b9ho+YpTGRIzUv7d9p3NnzypPnjyqWKmy+vYfqOBixZ0wLQCk5ZHHqlE9GqnJcxXl7+uhXQd/08CJK7Xjp+P2NSNea6jOzZ+Wj6ebvt91RL3HL1f88XOSpBpVS+jr9/vc9djPdpjocBwgszk1gCWpfv36WrBggcM2f39/J00DZI+ly1cq9dYt++PDhw+pW9fOqlOvviSpbNl/qGGjxgooUECXL13SnFkz1f3VV/TF19/I1dXVWWMDgN2cke1VNqSgurwZrVPnLqndC09oXdTrqtLyLZ08d0kDwmurR7tQvTpysY6dSNDIHo30+ayeqtzyLSWn3NS2XUcUVHuYwzFH9miksCdKEb/Ick6/BcJqtSogIMDha/r06Spfvrzc3d1VpEgR9ejRQ4mJifc8xq5duxQWFiZPT095eXmpatWq+uGHH+z7Y2NjVaNGDbm5ualIkSLq3bu3rl69mh2nB9yVn5+f8vn727+2bPpWRYoUVbXHn5AktWrdRlWrPa5ChQqrTNl/qFfvvjp9+pROnkh71RgAsltua041e76S3pi2Wlt/jNeRX89r3NwvFP/rOb36Yg1JUs/2YZrw3nqt3bRHew+dVNcRi1TA31tNwipKkm7cvKUzCVfsXwmXrqpRrQpatGabM08NhnB6AN+Ni4uLZsyYoX379ik6OloxMTEaPHjwPdd36NBBhQsX1vbt27Vjxw4NHTpUOXPmlCTFx8erfv36atmypXbv3q3ly5crNjZWvXr1yq7TAf7UjZQUrVu7Rs1atJTFYkmzPykpSZ+t+lSFChdWQECAEyYEAEc5XF2UI4errqfccNh+PfmGnq5cXEGF8qqAv7di/n3Avu9y4nVt33tMT1YIuusxG4VWUF5vdy3+jABG1nP6LRBr166Vh4eH/XGDBg308ccf2x8HBQXprbfeUvfu3TV79uy7HuP48eMaNGiQSpcuLUkqUaKEfV9kZKQ6dOigvn372vfNmDFDoaGhmjNnjnLnzp3meMnJyUpOTnbYZnO1ymq1/u3zBO4lJmajrly5oibNmjtsX/7hUk2dPEnXriUpKDhYc99boJy5cjlpSgD4r8SkZG3bdUTDXm2gg0fP6EzCZbWuX01PVghW/K/nFJDPS5J09sIVh+edTbiix/J63fWYnZpV14bv9+vE2YtZPT7g/CvAYWFhiouLs3/NmDFDGzdu1PPPP69ChQrJ09NTL7/8shISEpSUlHTXY/Tv319du3ZV7dq19fbbbys+Pt6+b9euXVq4cKE8PDzsX/Xq1VNqaqqOHj161+NFRkbK29vb4eudCZFZcv7Aqk8+0TPP1lT+/I85bH+hURMt/2SVPoheosDAIA0a0DfNX8wAwFm6vLlIFot05OtxuvTvaerZLlQrvvpBqam2DB+rUH4f1aleRtGrv8+CSYG0nB7A7u7uCgkJsX8lJyerUaNGqlChgj755BPt2LFDs2bNkiSlpKTc9RgRERHat2+fGjZsqJiYGJUtW1arVq2SJCUmJqpbt24Okb1r1y4dOnRIxYvf/R31w4YN06VLlxy+Bg0Zdte1wP04efKE/r3tO7Vo1SrNPk9PTwUGBqlqtcc1eeoMHT16RDEbNzhhSgBI6+hv51W363Tlrd5fJRqMUI2XJylnDlcdPXFep89fliTl9/N0eE7+vJ46k3A5zbFebvqUEi5d1drNu7NldsDpt0D80Y4dO5SamqrJkyfLxeV2n69YseIvn1eyZEmVLFlS/fr1U7t27bRgwQI1b95cVapU0U8//ZShj1WzWtPe7nD9ZsbOA0iPz1Z9Kj+/vKpRs9afrrNJks12z78EAoCzJF1PUdL1FPl4uqn202X0xrTPdOxEgk6du6SwJ0tp98+337zr6Z5bj5cL0nsfx6Y5RscmT2nZ2v/o5s3U7B4fhnrgAjgkJEQ3btzQzJkz1bhxY23dulVRUVH3XH/t2jUNGjRIrVq1UnBwsH777Tdt375dLVu2lCQNGTJETz31lHr16qWuXbvK3d1dP/30kzZs2KB33303u04LSCM1NVWfrfpUjZs2U44c//1P8bdff9X6r75Q9aefka+vn86cOa0P3p8nqzW3nq0Z6sSJAeC/alcvI4tF+vnYWRUv4q/x/Zrp56NntGjN7dsYZi37VkO61tfh4+d07ESCRvVoqFPnLmnNt7scjlPriZIKLpxPC1Z954zTgKEeuACuWLGipkyZogkTJmjYsGGqWbOmIiMj1bFjx7uud3V1VUJCgjp27KgzZ84oX758atGihUaPHi1JqlChgjZv3qw33nhDNWrUkM1mU/HixdWmTZvsPC0gjW3ff6dTp06qWYuWDttzWXPpxx0/aMniaF2+dFl58+VV1arVtGjph8qbN6+TpgUAR94euTXm9SYq9JiPLlxK0mffxGnUrM/tV3EnL9yoPG5WvftmO/l4uum7uHg16TlbySmO/6Qa3uxpfR8Xr5+PnXHGacBQFpvNlvG71Q3ELRAAHjW+j/NxkAAeLdd2pu9f953+JjgAAAAgOxHAAAAAMAoBDAAAAKMQwAAAADAKAQwAAACjEMAAAAAwCgEMAAAAoxDAAAAAMAoBDAAAAKMQwAAAADAKAQwAAACjEMAAAAAwCgEMAAAAoxDAAAAAMAoBDAAAAKMQwAAAADAKAQwAAACjEMAAAAAwCgEMAAAAoxDAAAAAMAoBDAAAAKMQwAAAADAKAQwAAACjEMAAAAAwCgEMAAAAoxDAAAAAMAoBDAAAAKMQwAAAADAKAQwAAACjEMAAAAAwCgEMAAAAoxDAAAAAMAoBDAAAAKMQwAAAADAKAQwAAACjEMAAAAAwCgEMAAAAoxDAAAAAMAoBDAAAAKMQwAAAADAKAQwAAACjEMAAAAAwCgEMAAAAoxDAAAAAMAoBDAAAAKMQwAAAADAKAQwAAACjEMAAAAAwCgEMAAAAoxDAAAAAMAoBDAAAAKMQwAAAADAKAQwAAACjEMAAAAAwCgEMAAAAoxDAAAAAMAoBDAAAAKMQwAAAADAKAQwAAACjEMAAAAAwCgEMAAAAoxDAAAAAMAoBDAAAAKMQwAAAADAKAQwAAACjEMAAAAAwCgEMAAAAoxDAAAAAMAoBDAAAAKMQwAAAADAKAQwAAACjEMAAAAAwCgEMAAAAoxDAAAAAMAoBDAAAAKMQwAAAADAKAQwAAACjEMAAAAAwCgEMAAAAoxDAAAAAMAoBDAAAAKMQwAAAADAKAQwAAACjEMAAAAAwCgEMAAAAoxDAAAAAMAoBDAAAAKMQwAAAADAKAQwAAACjEMAAAAAwCgEMAAAAoxDAAAAAMAoBDAAAAKMQwAAAADAKAQwAAACjEMAAAAAwCgEMAAAAoxDAAAAAMAoBDAAAAKMQwAAAADAKAQwAAACjEMAAAAAwCgEMAAAAoxDAAAAAMAoBDAAAAKMQwAAAADAKAQwAAACjEMAAAAAwCgEMAAAAoxDAAAAAMIrFZrPZnD0EgNuSk5MVGRmpYcOGyWq1OnscALhv/FzDg4gABh4gly9flre3ty5duiQvLy9njwMA942fa3gQcQsEAAAAjEIAAwAAwCgEMAAAAIxCAAMPEKvVqlGjRvFGEQCPDH6u4UHEm+AAAABgFK4AAwAAwCgEMAAAAIxCAAMAAMAoBDAAAMgSCxculI+Pj7PHANIggIEsYLFY/vQrIiLC2SMCQLqFh4ff9WfZ4cOHnT0a8LfkcPYAwKPo1KlT9j8vX75cI0eO1MGDB+3bPDw87H+22Wy6deuWcuTgP0cAD6769etrwYIFDtv8/f2dNA1wf7gCDGSBgIAA+5e3t7csFov98YEDB+Tp6akvv/xSVatWldVqVWxsrMLDw9WsWTOH4/Tt21e1atWyP05NTVVkZKSCg4Pl5uamihUrauXKldl7cgCMZLVaHX62BQQEaPr06Spfvrzc3d1VpEgR9ejRQ4mJifc8xq5duxQWFiZPT095eXmpatWq+uGHH+z7Y2NjVaNGDbm5ualIkSLq3bu3rl69mh2nB8MQwICTDB06VG+//bb279+vChUqpOs5kZGRWrRokaKiorRv3z7169dPL730kjZv3pzF0wJAWi4uLpoxY4b27dun6OhoxcTEaPDgwfdc36FDBxUuXFjbt2/Xjh07NHToUOXMmVOSFB8fr/r166tly5bavXu3li9frtjYWPXq1Su7TgcG4d9cAScZM2aM6tSpk+71ycnJGj9+vDZu3Kjq1atLkooVK6bY2FjNnTtXoaGhWTUqAGjt2rUOt281aNBAH3/8sf1xUFCQ3nrrLXXv3l2zZ8++6zGOHz+uQYMGqXTp0pKkEiVK2PdFRkaqQ4cO6tu3r33fjBkzFBoaqjlz5ih37txZcFYwFQEMOEm1atUytP7w4cNKSkpKE80pKSmqXLlyZo4GAGmEhYVpzpw59sfu7u7auHGjIiMjdeDAAV2+fFk3b97U9evXlZSUpDx58qQ5Rv/+/dW1a1ctXrxYtWvX1osvvqjixYtLun17xO7du7V06VL7epvNptTUVB09elRlypTJ+pOEMQhgwEnc3d0dHru4uOiPv5n8xo0b9j/fua9u3bp1KlSokMM6q9WaRVMCwG3u7u4KCQmxPz527JgaNWqk1157TePGjZOfn59iY2P1yiuvKCUl5a4BHBERofbt22vdunX68ssvNWrUKH300Udq3ry5EhMT1a1bN/Xu3TvN84oWLZql5wbzEMDAA8Lf31979+512BYXF2e/P65s2bKyWq06fvw4tzsAcLodO3YoNTVVkydPlovL7bcUrVix4i+fV7JkSZUsWVL9+vVTu3bttGDBAjVv3lxVqlTRTz/95BDZQFbhTXDAA+K5557TDz/8oEWLFunQoUMaNWqUQxB7enpq4MCB6tevn6KjoxUfH68ff/xRM2fOVHR0tBMnB2CikJAQ3bhxQzNnztSRI0e0ePFiRUVF3XP9tWvX1KtXL23atEm//PKLtm7dqu3bt9tvbRgyZIi+++479erVS3FxcTp06JA+++wz3gSHLEEAAw+IevXqacSIERo8eLAef/xxXblyRR07dnRYM3bsWI0YMUKRkZEqU6aM6tevr3Xr1ik4ONhJUwMwVcWKFTVlyhRNmDBB5cqV09KlSxUZGXnP9a6urkpISFDHjh1VsmRJtW7dWg0aNNDo0aMlSRUqVNDmzZv1888/q0aNGqpcubJGjhypggULZtcpwSAW2x9vOgQAAAAeYVwBBgAAgFEIYAAAABiFAAYAAIBRCGAAAAAYhQAGAACAUQhgAAAAGIUABgAAgFEIYAAAABiFAAYAA4SHh6tZs2b2x7Vq1VLfvn2zfY5NmzbJYrHo4sWL2f7aAHAHAQwAThQeHi6LxSKLxaJcuXIpJCREY8aM0c2bN7P0dT/99FONHTs2XWuJVgCPmhzOHgAATFe/fn0tWLBAycnJ+uKLL9SzZ0/lzJlTw4YNc1iXkpKiXLlyZcpr+vn5ZcpxAOBhxBVgAHAyq9WqgIAABQYG6rXXXlPt2rW1Zs0a+20L48aNU8GCBVWqVClJ0q+//qrWrVvLx8dHfn5+atq0qY4dO2Y/3q1bt9S/f3/5+Pgob968Gjx4sGw2m8Nr/vEWiOTkZA0ZMkRFihSR1WpVSEiI5s+fr2PHjiksLEyS5OvrK4vFovDwcElSamqqIiMjFRwcLDc3N1WsWFErV650eJ0vvvhCJUuWlJubm8LCwhzmBABnIYAB4AHj5uamlJQUSdI333yjgwcPasOGDVq7dq1u3LihevXqydPTU//617+0detWeXh4qH79+vbnTJ48WQsXLtQHH3yg2NhYXbhwQatWrfrT1+zYsaM+/PBDzZgxQ/v379fcuXPl4eGhIkWK6JNPPpEkHTx4UKdOndL06dMlSZGRkVq0aJGioqK0b98+9evXTy+99JI2b94s6Xaot2jRQo0bN1ZcXJy6du2qoUOHZtW3DQDSjVsgAOABYbPZ9M0332j9+vV6/fXXde7cObm7u+v999+33/qwZMkSpaam6v3335fFYpEkLViwQD4+Ptq0aZPq1q2radOmadiwYWrRooUkKSoqSuvXr7/n6/78889asWKFNmzYoNq1a0uSihUrZt9/53aJ/Pnzy8fHR9LtK8bjx4/Xxo0bVb16dftzYmNjNXfuXIWGhmrOnDkqXry4Jk+eLEkqVaqU9uzZowkTJmTidw0AMo4ABgAnW7t2rTw8PHTjxg2lpqaqffv2ioiIUM+ePVW+fHmH+3537dqlw4cPy9PT0+EY169fV3x8vC5duqRTp07pySeftO/LkSOHqlWrluY2iDvi4uLk6uqq0NDQdM98+PBhJSUlqU6dOg7bU1JSVLlyZUnS/v37HeaQZI9lAHAmAhgAnCwsLExz5sxRrly5VLBgQeXI8d8fze7u7g5rExMTVbVqVS1dujTNcfz9/f/W67u5uWX4OYmJiZKkdevWqVChQg77rFbr35oDALILAQwATubu7q6QkJB0ra1SpYqWL1+u/Pnzy8vL665rChQooH//+9+qWbOmJOnmzZvasWOHqlSpctf15cuXV2pqqjZv3my/BeJ/3bkCfevWLfu2smXLymq16vjx4/e8clymTBmtWbPGYdu2bdv++iQBIIvxJjgAeIh06NBB+fLlU9OmTfWvf/1LR48e1aZNm9S7d2/99ttvkqQ+ffro7bff1urVq3XgwAH16NHjTz/DNygoSJ06dVKXLl20evVq+zFXrFghSQoMDJTFYtHatWt17tw5JSYmytPTUwMHDlS/fv0UHR2t+Ph4/fjjj5o5c6aio6MlSd27d9ehQ4c0aNAgHTx4UMuWLdPChQuz+lsEAH+JAAaAh0iePHm0ZcsWFS1aVC1atFCZMmX0yiuv6Pr16/YrwgMGDNDLL7+sTp06qXr16vL09FTz5s3/9Lhz5sxRq1at1KNHD5UuXVqvvvqqrl69KkkqVKiQRo8eraFDh+qxxx5Tr169JEljx47ViBEjFBkZqTJlyqh+/fpat26dgoODJUlFixbVJ598otWrV6tixYqKiorS+PHjs/C7AwDpY7Hd610RAAAAwCOIK8AAAAAwCgEMAAAAoxDAAAAAMAoBDAAAAKMQwAAAADAKAQwAAACjEMAAAAAwCgEMAAAAoxDAAAAAMAoBDAAAAKMQwAAAADDK/wHk7F9NN+shaAAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# 실제 라벨과 예측 라벨\n",
        "actual = test_target\n",
        "predicted = model.predict(test_data)\n",
        "predicted_labels = (predicted > 0.5).astype(int)\n",
        "\n",
        "# 혼동 행렬 계산\n",
        "cm = confusion_matrix(actual, predicted_labels)\n",
        "\n",
        "# 혼동 행렬 시각화\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap='Blues', cbar=False)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.xticks(np.arange(2) + 0.5, ['True', 'False'])\n",
        "plt.yticks(np.arange(2) + 0.5, ['True', 'False'], rotation=0)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Callback 사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\qq\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# 모델 생성\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(train_data.shape[1], )),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# 학습된 가중치 불러오기\n",
        "model.load_weights('best_model_wine.keras')\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['accuracy', Precision(), Recall()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8526 - loss: 0.1053 - precision_2: 0.8970 - recall_2: 0.9079 \n",
            "loss: 0.10216907411813736 accuracy: 0.8623076677322388 precision: 0.9017050862312317 recall: 0.9173469543457031\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[0.08571302]], dtype=float32)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 모델 평가\n",
        "results = model.evaluate(test_data, test_target)\n",
        "print(f'loss: {results[0]} accuracy: {results[1]} precision: {results[2]} recall: {results[3]}')\n",
        "\n",
        "# 예측\n",
        "model.predict(tf.constant([[9.4, 1.8, 3.5]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "연습문제_3_K_Fold와_그리드서치_와인.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
