{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJtAdaMtGn6T"
      },
      "source": [
        "# LSTM을 이용하여 텍스트 생성하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wCIJkMG5Go1f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "id": "BhA4cyOgGrTP",
        "outputId": "eb3a9763-f7dc-4380-def7-8a864d48352f"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('ArticlesApril2018.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNK4ABDtGyMH",
        "outputId": "b8ac8eda-6593-4f5a-8277-73fbb953dfd2"
      },
      "outputs": [],
      "source": [
        "# headline에 결측치가 있는지 확인\n",
        "print(df['headline'].isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGeLDG7EGz7P",
        "outputId": "55ff7eef-f726-4f41-d787-16f0067af032"
      },
      "outputs": [],
      "source": [
        "# 헤드라인의 값들을 리스트로 저장\n",
        "hl = df['headline'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "379FN70HG2XX",
        "outputId": "bae6a114-8d25-461d-c151-bffbded4800c"
      },
      "outputs": [],
      "source": [
        "# 현재 샘플의 개수 출력\n",
        "print(len(hl))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zy8-4-AyG9Hv",
        "outputId": "8bf17e8e-a401-4a12-de70-23dc4abcfded"
      },
      "outputs": [],
      "source": [
        "# Unknown 값을 가진 샘플 제거\n",
        "filtered_headline = []\n",
        "\n",
        "for word in hl:\n",
        "    if word !='Unknown':\n",
        "        filtered_headline.append(word)\n",
        "\n",
        "# Unknown 값 제거 후 샘플의 개수 출력\n",
        "print(len(filtered_headline))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLGQ7s_2G_3W",
        "outputId": "90283ab8-8a0c-4920-e659-be03e117803d"
      },
      "outputs": [],
      "source": [
        "# 구두점(!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~)불러오는 코드\n",
        "from string import punctuation\n",
        "\n",
        "# 데이터 전처리 함수\n",
        "def repreprocessing(raw_sentence):\n",
        "    # 아스키코드로 디코딩하는 과정에서 아스키 코드로 표현할 수 없는 문자는 사라짐\n",
        "    preproceseed_sentence = raw_sentence.encode(\"utf8\").decode(\"ascii\",'ignore')\n",
        "    # 구두점 제거 및 소문자화\n",
        "    return ''.join(word for word in preproceseed_sentence if word not in punctuation).lower()\n",
        "\n",
        "# filtered_headline 각 요소에 대해 데이터 전처리 과정 수행\n",
        "preprocessed_headline = []\n",
        "for i in filtered_headline:\n",
        "    pre = repreprocessing(i)\n",
        "    preprocessed_headline.append(pre)\n",
        "\n",
        "# 전처리 완료된 새로운 리스트 생성\n",
        "preprocessed_headline[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18-SLG1YHFb3",
        "outputId": "ea9a9626-9406-4e54-eed7-575601cd8e35"
      },
      "outputs": [],
      "source": [
        "# 토큰화 및 단어 집합의 크기(vocab_size) 계산\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(preprocessed_headline)\n",
        "vocab_size = len(tokenizer.word_index) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9PRhbYzHmrX",
        "outputId": "d0acbe0e-9034-4626-e08f-40fd3ef3b7ea"
      },
      "outputs": [],
      "source": [
        "# 문장을 분해하여 sequence 생성\n",
        "sequences = []\n",
        "\n",
        "for sentence in preprocessed_headline:\n",
        "    encoded = tokenizer.texts_to_sequences([sentence])[0]\n",
        "\n",
        "    for i in range(1, len(encoded)):\n",
        "        sequence = encoded[: i+1]\n",
        "        sequences.append(sequence)\n",
        "sequences[:15]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DFDdcHXIO03",
        "outputId": "2d1e7948-f77f-4afb-d7d6-7659dbb67108"
      },
      "outputs": [],
      "source": [
        "# 샘플(sequence)의 최대 길이 구하기\n",
        "max_len = max(len(l) for l in sequences)\n",
        "\n",
        "lens = []\n",
        "for line in sequences:\n",
        "    lens.append(len(line))\n",
        "max_len = max(lens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gI_BNPqGIUNv",
        "outputId": "3a4fed40-3ecc-4f19-b079-c65af8fe9d80"
      },
      "outputs": [],
      "source": [
        "# 시퀀스 패딩\n",
        "sequences = pad_sequences(sequences, maxlen=max_len)\n",
        "sequences[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "AS_Xeb68IW7n"
      },
      "outputs": [],
      "source": [
        "# 시퀀스 넘파이 배열로 변환\n",
        "sequences = np.array(sequences)\n",
        "\n",
        "# 마지막 단어를 제외한 부분을 입력 데이터로 사용\n",
        "X = sequences[:, :-1]\n",
        "\n",
        "# 마지막 단어를 출력 데이터로 사용\n",
        "y = sequences[:, -1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQxwog4tIZOn",
        "outputId": "28b61b65-245b-41f5-e30e-71459dd4aa1b"
      },
      "outputs": [],
      "source": [
        "# data(X) 3행 출력\n",
        "X[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymQ9On9bIZ8f",
        "outputId": "b5dbd0d1-e98a-4660-c11d-7bc5cfbc9eac"
      },
      "outputs": [],
      "source": [
        "# target(y) 3행 출력\n",
        "y[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "BfI0f9ChIbbP"
      },
      "outputs": [],
      "source": [
        "# target(y)에 대해 원 핫 인코딩\n",
        "y = to_categorical(y, num_classes=vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "HqNmAdYJIcUP"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Dense, LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUQE1WpzIkDP",
        "outputId": "8090a020-4647-4290-b3b5-11e03a4ae846"
      },
      "outputs": [],
      "source": [
        "# 모델 생성\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 64))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 모델 학습\n",
        "model.fit(X, y, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "J6Lqo_uRIq2X"
      },
      "outputs": [],
      "source": [
        "# 문장 생성기(RNN과 완전 동일)\n",
        "# 모델, 토크나이저, 현재 단어, 반복할 횟수\n",
        "def sentence_generation(model, tokenizer, current_word, n):\n",
        "    init_word = current_word\n",
        "    sentence = ''\n",
        "\n",
        "    for _ in range(n):\n",
        "        encoded = tokenizer.texts_to_sequences([current_word])[0]\n",
        "        encoded = pad_sequences([encoded], maxlen=max_len-1, padding='pre')\n",
        "\n",
        "        result = model.predict(encoded, verdose=0)\n",
        "        result = np.argmax(result, axis=1)\n",
        "\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == result:\n",
        "                break\n",
        "\n",
        "        current_word = current_word + ' ' + word\n",
        "\n",
        "        sentence = sentence + ' ' + word\n",
        "\n",
        "    sentence = init_word + sentence\n",
        "    return sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAfJZAD4JIUM",
        "outputId": "3a61fef1-8790-48c7-e0b4-cee24472dbde"
      },
      "outputs": [],
      "source": [
        "print(sentence_generation(model, tokenizer, 'i want', 10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeXp2oTZJLiS",
        "outputId": "00e7fa2c-821a-4bf1-ada3-736c227865fd"
      },
      "outputs": [],
      "source": [
        "print(sentence_generation(model, tokenizer, 'how', 10))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Text generation with an RNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
